{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pewnego wieczoru w malowicznym Zakopanem - stolicy ówczesnego świata artystycznego Młodej Polski - spotkali się Kazimierz Przerwa-Tetmajer oraz Henryk Sienkiewicz: \n",
    "\n",
    "    - Kazimierz Przerwa-Tetmajer, kłaniam się - powiedział poeta. \n",
    "    - Miło mi. Henryk *bez przerwy* Sienkiewicz - odpowiedział powieściopisarz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation, digits\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import special\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import re\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cel zadania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W poniższej pracy skupię się na utworzeniu reprezentacji word2vec dla słów wchodzących w skład korpusu utworzonego na bazie twórczości <s>Henryka Sienkiewicza</s> polskich pozytywistów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane tekstowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do dyspozycji mam następujące utwory, z których każdy zapisany jest w oddzielnym pliku tekstowym. Korpus zostanie utworzony z powieści, opowiadań i nowelek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bartek-zwyciezca.txt\n",
      "bez-dogmatu.txt\n",
      "janko-muzykant.txt\n",
      "krzyzacy.txt\n",
      "latarnik.txt\n",
      "list-otwarty-polaka-do-ministra-rosyjskiego.txt\n",
      "na-jasnym-brzegu.txt\n",
      "na-marne.txt\n",
      "na-oceanie-atlantyckim.txt\n",
      "na-polu-chwaly.txt\n",
      "niewola-tatarska.txt\n",
      "ogniem-i-mieczem.txt\n",
      "pan-wolodyjowski.txt\n",
      "potop.txt\n",
      "quo-vadis.txt\n",
      "rodzina-polanieckich.txt\n",
      "sienkiewicz-badz-blogoslawiona.txt\n",
      "sienkiewicz-bajka.txt\n",
      "sienkiewicz-co-sie-raz-stalo-w-sydonie.txt\n",
      "sienkiewicz-czy-ci-najmilszy.txt\n",
      "sienkiewicz-diokles.txt\n",
      "sienkiewicz-dwie-laki.txt\n",
      "sienkiewicz-hkt.txt\n",
      "sienkiewicz-jako-sie-pan-lubomirski-nawrocil.txt\n",
      "sienkiewicz-legenda-zeglarska.txt\n",
      "sienkiewicz-na-olimpie.txt\n",
      "sienkiewicz-orso.txt\n",
      "sienkiewicz-plomyk.txt\n",
      "sienkiewicz-pojdzmy-za-nim.txt\n",
      "sienkiewicz-przygoda-arystoklesa.txt\n",
      "sienkiewicz-sabalowa-bajka.txt\n",
      "sienkiewicz-sachem.txt\n",
      "sienkiewicz-sad-ozyrysa.txt\n",
      "sienkiewicz-toast.txt\n",
      "sienkiewicz-u-bramy-raju.txt\n",
      "sienkiewicz-we-mgle.txt\n",
      "sienkiewicz-wesele.txt\n",
      "sienkiewicz-wspomnienie-z-maripozy.txt\n",
      "sienkiewicz-wyrok-zeusa.txt\n",
      "sienkiewicz-za-chlebem.txt\n",
      "sienkiewicz-z-dawnych-dziejow.txt\n",
      "sienkiewicz-z-kurzem-krwi-bratniej.txt\n",
      "sienkiewicz-z-pamietnika-poznanskieg-nauczyciela.txt\n",
      "szkice-weglem.txt\n",
      "Wiry.txt\n",
      "w-pustyni-i-w-puszczy.txt\n"
     ]
    }
   ],
   "source": [
    "!ls ./data/henryk_sienkiewicz/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W folderze z danymi znajduje się następująca liczba plików:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "! find ./data/henryk_sienkiewicz/ -maxdepth 1 -type f -name \"*.txt\" -printf x | wc -c "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "które ważą łącznie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16M\t./data/henryk_sienkiewicz/\n"
     ]
    }
   ],
   "source": [
    "! du -sbh ./data/henryk_sienkiewicz/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiekszość plików została pobrana ze strony [Wolne Lektury](https://wolnelektury.pl/), kilka natomiast z [Wikiźródła](https://pl.wikisource.org/wiki/Wiki%C5%BAr%C3%B3d%C5%82a:Strona_g%C5%82%C3%B3wna)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Czyszczenie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Książki pobrane z Wolnych Lektur są opatrzone komentarzem na początku pliku. Konieczne jest usunięcie numeru ISBN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Henryk Sienkiewicz\n",
      "\n",
      "Bajka\n",
      "\n",
      "ISBN 978-83-288-2802-5\n",
      "\n",
      "\n",
      "Za górami, za morzami, w dalekiej krainie czarów, przy kolebce małej księżniczki zebrały się dobre wróżki ze swą królową na czele.\n",
      "\n",
      "I gdy otoczywszy księżniczkę patrzyły na uśpioną twarzyczkę dzieciny, królowa ich rzekła:\n"
     ]
    }
   ],
   "source": [
    "! head ./data/raw_examples/sienkiewicz-bajka.txt -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na końcu pliku znajduje się komentarz, który także podlega usunięciu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To rzekłszy królowa wróżek pochyliła się nad śpiącą dzieciną i dotknąwszy rękami jej serca rzekła:\n",
      "\n",
      "— Bądź dobrą!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----\n",
      "Ta lektura, podobnie jak tysiące innych, dostępna jest na stronie wolnelektury.pl.\n",
      "Wersja lektury w opracowaniu merytorycznym i krytycznym (przypisy i motywy) dostępna jest na stronie http://wolnelektury.pl/katalog/lektura/sienkiewicz-bajka.\n",
      "\n",
      "Utwór opracowany został w ramach projektu Wolne Lektury przez fundację Nowoczesna Polska.\n",
      "\n",
      "Ten utwór nie jest objęty majątkowym prawem autorskim i znajduje się w domenie publicznej, co oznacza że możesz go swobodnie wykorzystywać, publikować i rozpowszechniać. Jeśli utwór opatrzony jest dodatkowymi materiałami (przypisy, motywy literackie etc.), które podlegają prawu autorskiemu, to te dodatkowe materiały udostępnione są na licencji Creative Commons Uznanie Autorstwa – Na Tych Samych Warunkach 3.0 PL (http://creativecommons.org/licenses/by-sa/3.0/).\n",
      "\n",
      "Tekst opracowany na podstawie: Henryk Sienkiewicz, Baśnie i legendy, wybór, wstęp, przypisy Tomasz Jodełko-Burzecki, Ludowa Spółdzielnia Wydawnicza, Warszawa 1986\n",
      "\n",
      "Wydawca: Fundacja Nowoczesna Polska\n",
      "\n",
      "Publikacja zrealizowana w ramach projektu Wolne Lektury (http://wolnelektury.pl). Reprodukcja cyfrowa wykonana przez fundację Nowoczesna Polska z egzemplarza pochodzącego ze zbiorów Marty Niedziałkowskiej. Dofinansowano ze środków Narodowego Centrum Kultury w ramach Programu Narodowego Centrum Kultury - Kultura - Interwencje.\n",
      "\n",
      "Opracowanie redakcyjne i przypisy: Paulina Choromańska, Paulina Ołtusek, Aleksandra Sekuła.\n",
      "\n",
      "ISBN 978-83-288-2802-5\n"
     ]
    }
   ],
   "source": [
    "! tail ./data/raw_examples/sienkiewicz-bajka.txt -n 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pliki pobrane z Wikiźródeł także opatrzone są zbędnymi w analizie komentarzami. Informacja dotyczy na przykład faktu pobrania pliku z Wikiźródeł:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/henryk_sienkiewicz/na-polu-chwaly.txt:6036:W publikacji została zachowana oryginalna ortografia, oczywiste błędy w druku zostały poprawione przez redaktorów Wikiźródeł.\n",
      "./data/henryk_sienkiewicz/Wiry.txt:6137:W publikacji została zachowana oryginalna ortografia, oczywiste błędy w druku zostały poprawione przez redaktorów Wikiźródeł.\n"
     ]
    }
   ],
   "source": [
    "! grep -rnw ./data/henryk_sienkiewicz// -e 'Wikiźródeł'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informacje zbędne znajdują się na początku i na końcu plików. Automatycznie (i bezpiecznie) można usunąć linie zawierające słowa *ISBN*, *Wolne lektury*, *wolnelektury*, *Wikiźródła*, *Creative Commons*, *Opracowanie redakcyjne*. Używam poniższego skryptu. Usuwam wszystkie kolejne linie po wystąpieniu *-----* lub *Wesprzyj Wolne Lektury*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "for filename in *.txt; do\n",
      "\tsed -i.bak '/creativecommons\\|ISBN\\|wolnelektury\\|Wolne Lektury\\|*Wikiźród*\\|Creative Commons\\|http/d' $filename\n",
      "\tsed -i.bak '/-----/,+100 d' $filename\n",
      "\tsed -i.bak '/Wesprzyj Wolne Lektury/,+100 d' $filename\n",
      "done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! cat ./scripts/delete_text.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reszta niepotrzebnego tekstu została usunięta ręcznie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Czyszczenie tekstu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po uzyskaniu właściwego tekstu utworów Sienkiewicza mogę przejść do czyszczenia zawartości plików ze znaków interpunkcyjnych i cyfr oraz zamianę wielkich liter na małe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file):\n",
    "    # file in read-only mode\n",
    "    with open(file, 'r') as file:\n",
    "        # text is list of lines\n",
    "        text = file.readlines()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W plikach przekonwertowanych z `.mobi` do `.txt` mamy znaki, które bez odpowiedniego przetworzenia dyskwalfikują słowa z dalszej analizy. `\\xad` to oznaczenie miękkiego podziału słowa (ang. *soft hyphen*), który informuje, w którym miejscu słowo może zostać podzielone, jeżeli wstawienie całego słowa do linijki powoduje przekroczenie limitu znaków w tej linijce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ro\\xaddo\\xadwi\\xadci Egip\\xadcja\\xadnie mie\\xadli bar\\xadwę skó\\xadry mie\\xaddzia\\xadną7, czym cheł\\xadpi\\xadli się, gar\\xaddząc jed\\xadno\\xadcze\\xadśnie czar\\xadny\\xadmi Etio\\xadpa\\xadmi, żół\\xadty\\xadmi Se\\xadmi\\xadta\\xadmi i bia\\xadły\\xadmi Eu\\xadro\\xadpej\\xadczy\\xadka\\xadmi. Ten ko\\xadlor skó\\xadry, po\\xadzwa\\xadla\\xadją\\xadcy od\\xadróż\\xadnić swo\\xadje\\xadgo od ob\\xadce\\xadgo, przy\\xadczy\\xadniał się do utrzy\\xadma\\xadnia na\\xadro\\xaddo\\xadwej jed\\xadno\\xadści sil\\xadniej ani\\xadże\\xadli re\\xadli\\xadgia, któ\\xadrą moż\\xadna przy\\xadjąć, al\\xadbo ję\\xadzyk, któ\\xadre\\xadgo moż\\xadna się wy\\xaduczyć.\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_line = load_file(\"./data/pozytywizm/prus/faraon.txt\")[241]\n",
    "invalid_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rodowici Egipcjanie mieli barwę skóry miedzianą7, czym chełpili się, gardząc jednocześnie czarnymi Etiopami, żółtymi Semitami i białymi Europejczykami. Ten kolor skóry, pozwalający odróżnić swojego od obcego, przyczyniał się do utrzymania narodowej jedności silniej aniżeli religia, którą można przyjąć, albo język, którego można się wyuczyć.\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_line.replace(\"\\xad\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pojawia się kolejny problem: słowa z przypisami (np. *miedzianą7*) muszą być oczyszczane z liczb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'miedzianą'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_w_footnote = 'miedzianą7'\n",
    "word_w_footnote.rstrip(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(line):\n",
    "    # delete trailing \\n\n",
    "    line = line.rstrip()\n",
    "    # get tokens\n",
    "    tokens = line.split()\n",
    "    # remove punctuation\n",
    "    table = str.maketrans('', '', punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove soft hyphens\n",
    "    tokens = [w.replace(\"\\xad\", \"\") for w in tokens]\n",
    "    # remove footnote refs\n",
    "    tokens = [w.rstrip(digits) for w in tokens]\n",
    "    # leave only letters\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # no capital letters\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_count = Counter()\n",
    "\n",
    "for filename in os.listdir('./data/henryk_sienkiewicz/'):\n",
    "    for text_line in load_file(os.path.join('./data/henryk_sienkiewicz/', filename)):\n",
    "        if text_line == \"\\n\":\n",
    "            continue\n",
    "        clean_tokens = clean_line(text_line)\n",
    "        vocabulary_count.update(clean_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okazuje się, że korpus oparty jedynie o twórczość Henryka Sienkiewicza ma tylko ponad 2 mln słów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2060450"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(vocabulary_count.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodatkowe dane tekstowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konieczne jest dodanie innych autorów. Dodaję utwory autorów epoki pozytywizmu (w której duchu z resztą tworzył Sienkiewicz): Stefan Żeromski, Bolesław Prus, Władysław Reymont, Eliza Orzeszkowa, Maria Konopnicka oraz Michał Bałucki. Liczba nowych plików, które dochodzą to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "! find ./data/pozytywizm/ -type f -name \"*.txt\" -printf x | wc -c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33M\t./data/pozytywizm/\n"
     ]
    }
   ],
   "source": [
    "! du -sbh ./data/pozytywizm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pliki czyszczę nowym skryptem, który na podstawie prób i błędów rozszerzył funkcjonalność poprzedniego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "for filename in $(find ./pozytywizm -name '*.txt'); do\n",
      "\tsed -i '/creativecommons\\|ISBN\\|wolnelektury\\|Wolne Lektury\\|*Wikiźród*\\|Creative Commons\\|http\\|Jak możesz pomóc\\?\\|Co roku do domeny publicznej przechodzi/d' $filename\n",
      "\tsed -i '/-----/,$d' $filename\n",
      "\tsed -i '/Wesprzyj Wolne Lektury!/,$d' $filename\n",
      "\tsed -i '/Przekaż 1% podatku na rozwój Wolnych Lektur:/,$d' $filename\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "! cat ./data/maly_skrypt.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla nowych plików tekstowych powtarzam kroki wykonane dla plików zawierających twórczość Henryka Sienkiewicza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author_dir, _, _ in os.walk(\"./data/pozytywizm/\"):\n",
    "    if author_dir == './data/pozytywizm/':\n",
    "        continue\n",
    "    for file in os.listdir(author_dir):\n",
    "        for text_line in load_file(os.path.join(author_dir, file)):\n",
    "            if text_line == \"\\n\":\n",
    "                continue\n",
    "            clean_tokens = clean_line(text_line)\n",
    "            vocabulary_count.update(clean_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po wprowadzeniu utworów innych autorów z epoki pozytywizmu uzyskałem korpus liczący więcej niż 5,8 mln słów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5876081"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(vocabulary_count.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statystyki korpusu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 najczęściej występujących słów w korpusie to spójniki i partykuły:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 214558),\n",
       " ('się', 150620),\n",
       " ('w', 135190),\n",
       " ('nie', 106474),\n",
       " ('na', 105147),\n",
       " ('z', 101554),\n",
       " ('do', 65563),\n",
       " ('a', 63111),\n",
       " ('to', 62638),\n",
       " ('że', 59799)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następująca liczba unikalnych słów znajduje się w korpusie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262178"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(vocabulary_count.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ze względu na bogatą morfologię języka polskiego rzeczywiste użycie danego słowa jest w pewnym sensie niedoszacowane. Załóżmy, że chcemy stwierdzić czy dany tekst dotyczy *kota*. Samo wyszukanie w `vocabulary_count` klucza `kot` nie wystarcza, ponieważ nie uwzględniamy różnych form tego słowa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_items = [k for k, v in vocabulary_count.items() if v == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duża liczba form wyrazów występuje tylko raz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110588"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(single_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykładowe słowa występujące tylko raz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['leciałby',\n",
       " 'uszlachcony',\n",
       " 'zdradny',\n",
       " 'nawarzyć',\n",
       " 'wylegitymują',\n",
       " 'wirgiliuszem',\n",
       " 'jubes',\n",
       " 'renovare',\n",
       " 'zczezł',\n",
       " 'rozdrapią',\n",
       " 'odmładzającej']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_items[12560:12571]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prawo Zipfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prawo Zipfa mówi, że częstotliwość występowania słowa jest wprost proporcjonalna do rangi (kolejności). Poniżej sprawdzam czy prawo zachodzi dla analizowanego korpusu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(vocabulary_count, orient='index').reset_index()\n",
    "df = df.rename(columns={'index': 'word', 0: 'count'})\n",
    "df = df.sort_values(by=['count'], ascending=False)\n",
    "df = df.reset_index()\n",
    "df_for_vis = df.truncate(after=25)\n",
    "del df['index']\n",
    "del df_for_vis['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rysunek pokazuje, że nie mamy raczej do czynienia z rozkładem Zipfa, w którym pierwsze słowo występuje dwa razy częściej niż drugie, drugie dwa razy częściej niż trzecie itd.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v2+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v2.6.0.json",
       "config": {
        "view": {
         "height": 300,
         "width": 400
        }
       },
       "data": {
        "name": "data-20e67a8795cc7b8faf86798c9aa862a9"
       },
       "datasets": {
        "data-20e67a8795cc7b8faf86798c9aa862a9": [
         {
          "count": 214558,
          "word": "i"
         },
         {
          "count": 150620,
          "word": "się"
         },
         {
          "count": 135190,
          "word": "w"
         },
         {
          "count": 106474,
          "word": "nie"
         },
         {
          "count": 105147,
          "word": "na"
         },
         {
          "count": 101554,
          "word": "z"
         },
         {
          "count": 65563,
          "word": "do"
         },
         {
          "count": 63111,
          "word": "a"
         },
         {
          "count": 62638,
          "word": "to"
         },
         {
          "count": 59799,
          "word": "że"
         },
         {
          "count": 34146,
          "word": "ale"
         },
         {
          "count": 33115,
          "word": "jak"
         },
         {
          "count": 32498,
          "word": "o"
         },
         {
          "count": 30012,
          "word": "co"
         },
         {
          "count": 29228,
          "word": "po"
         },
         {
          "count": 27737,
          "word": "za"
         },
         {
          "count": 26876,
          "word": "tak"
         },
         {
          "count": 22391,
          "word": "od"
         },
         {
          "count": 21976,
          "word": "już"
         },
         {
          "count": 20794,
          "word": "jej"
         },
         {
          "count": 19744,
          "word": "jest"
         },
         {
          "count": 18381,
          "word": "go"
         },
         {
          "count": 17687,
          "word": "mu"
         },
         {
          "count": 17629,
          "word": "bo"
         },
         {
          "count": 16691,
          "word": "pan"
         },
         {
          "count": 16607,
          "word": "tylko"
         }
        ]
       },
       "encoding": {
        "x": {
         "field": "word",
         "sort": {
          "field": "word",
          "op": "count",
          "order": "ascending"
         },
         "type": "nominal"
        },
        "y": {
         "field": "count",
         "type": "quantitative"
        }
       },
       "mark": "bar"
      },
      "image/png": "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",
      "text/plain": [
       "<VegaLite 2 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(df_for_vis).mark_bar().encode(\n",
    "    x=alt.X('word', sort=alt.EncodingSortField(field='word', op='count', order='ascending')),\n",
    "    y='count'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokonam dokładniejszych testów pozwalających określić czy uzyskane zliczenia słów mają rozkład Zipfa. Zaczynam od zaaplikowania logarytmu do rangi oraz zliczeń tym razem na pełnych danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rank'] = df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_count'] = np.log(df['count'])\n",
    "df['log_rank'] = np.log(df['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>rank</th>\n",
       "      <th>log_count</th>\n",
       "      <th>log_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>214558</td>\n",
       "      <td>1</td>\n",
       "      <td>12.276335</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>się</td>\n",
       "      <td>150620</td>\n",
       "      <td>2</td>\n",
       "      <td>11.922515</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w</td>\n",
       "      <td>135190</td>\n",
       "      <td>3</td>\n",
       "      <td>11.814436</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nie</td>\n",
       "      <td>106474</td>\n",
       "      <td>4</td>\n",
       "      <td>11.575656</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>na</td>\n",
       "      <td>105147</td>\n",
       "      <td>5</td>\n",
       "      <td>11.563115</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word   count  rank  log_count  log_rank\n",
       "0    i  214558     1  12.276335  0.000000\n",
       "1  się  150620     2  11.922515  0.693147\n",
       "2    w  135190     3  11.814436  1.098612\n",
       "3  nie  106474     4  11.575656  1.386294\n",
       "4   na  105147     5  11.563115  1.609438"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ze względu na duży rozmiar pliku, na którego podstawie zostanie zrenderowany wykres (Altair trzyma wykresy jako JSON) zapisuję wykres do oddzielnego pliku:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('json_dir')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.data_transformers.enable('json')\n",
    "\n",
    "altair_data_dir='altair_graphs'\n",
    "\n",
    "def json_dir(data, data_dir=altair_data_dir):\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    return alt.pipe(data, alt.to_json(filename=data_dir + '/{prefix}-{hash}.{extension}') )\n",
    "\n",
    "\n",
    "alt.data_transformers.register('json_dir', json_dir)\n",
    "alt.data_transformers.enable('json_dir', data_dir='altair_graphs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykres (interaktywny) dla wszystkich punktów pokazuje raczej prostą linię:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v2+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v2.6.0.json",
       "config": {
        "view": {
         "height": 300,
         "width": 400
        }
       },
       "data": {
        "format": {
         "type": "json"
        },
        "url": "altair_graphs/altair-data-ccb4bf2275b35b8faf9ca4f8c1abfe91.json"
       },
       "encoding": {
        "tooltip": [
         {
          "field": "word",
          "type": "nominal"
         },
         {
          "field": "count",
          "type": "quantitative"
         }
        ],
        "x": {
         "field": "log_rank",
         "type": "quantitative"
        },
        "y": {
         "field": "log_count",
         "type": "quantitative"
        }
       },
       "mark": {
        "size": 20,
        "type": "circle"
       },
       "selection": {
        "selector001": {
         "bind": "scales",
         "encodings": [
          "x",
          "y"
         ],
         "mark": {
          "fill": "#333",
          "fillOpacity": 0.125,
          "stroke": "white"
         },
         "on": "[mousedown, window:mouseup] > window:mousemove!",
         "resolve": "global",
         "translate": "[mousedown, window:mouseup] > window:mousemove!",
         "type": "interval",
         "zoom": "wheel!"
        }
       }
      },
      "image/png": "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",
      "text/plain": [
       "<VegaLite 2 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(df).mark_circle(size=20).encode(\n",
    "    x='log_rank',\n",
    "    y='log_count',\n",
    "    tooltip=['word', 'count']\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-gramy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzam najczęstsze 2-gramy i 3-gramy dla analizowanego korpusu. Plik ładuje się jako lista linii. W utworach zdarza się, że zdania są oddzielone od siebie linią. W takich przypadkach można bezpiecznie założyć, że kolejne dwa zdania w oryginale występują tuż po sobie i składanie n-gramu z ostatnich elementów pierwszego zdania (*Rodowici Egipcjanie...*) z pierwszymi elementami kolejnego zdania (*Z biegiem czasu...*) ma sens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'rodowici egipcjanie mieli barwę skóry miedzianą czym chełpili się gardząc jednocześnie czarnymi etiopami żółtymi semitami i białymi europejczykami ten kolor skóry pozwalający odróżnić swojego od obcego przyczyniał się do utrzymania narodowej jedności silniej aniżeli religia którą można przyjąć albo język którego można się wyuczyć',\n",
       " '',\n",
       " 'z biegiem czasu jednak kiedy państwowy gmach zaczął pękać do kraju coraz liczniej napływały obce pierwiastki osłabiały one spójność rozsadzały społeczeństwo a nareszcie zalały i rozpuściły w sobie pierwotnych mieszkańców kraju',\n",
       " '']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\" \".join(clean_line(line)) for line in load_file('./data/pozytywizm/prus/faraon.txt')[240:245]] #używam czyszczenia, bo Faraon był konwertowany z .mobi do .txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W innych przypadkach zależność ciągu myślowego nie jest taka jasna, np.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I oto jak spotkaliśmy się po raz ostatni.\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Umilkła. W głębi pokoju, dotykane dalekim światłem lampy, mętnie majaczą iskry pozłot na książkach i zarysy obrazów na ścianach. Za oknami stoi bezoka noc listopadowa i w czarnym łonie toczy westchnienia coraz głębsze, coraz głuchsze, coraz dalsze…\\n',\n",
       " '\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_file('./data/pozytywizm/orzeszkowa/gloria-victis-dziwna-historia.txt')[546:555]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W jeszcze innym przypadku n-gramy nie powinny być tworzone na bazie ostatnich słów zdania poprzedniego i pierwszych słów zdania następnego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jakże nie wiem odparł szlachcic to pan tomasz billewicz miecznik rosieński wszyscy go tu znają bo to dawny radziwiłłowski sługa i przyjaciel',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'rozdział xiii',\n",
       " '',\n",
       " '',\n",
       " 'książę nie pokazał się tego dnia szlachcie aż do wieczora obiadował bowiem z posłami i kilku dygnitarzami z którymi poprzednio naradę był składał przyszły jednak rozkazy do pułkowników żeby nadworne pułki radziwiłłowskie a zwłaszcza regimenty piechoty pod cudzoziemskimi oficerami stały w pogotowiu w powietrzu pachniało prochem zamek lubo nieobronny otoczony był wojskiem jak gdyby pod jego murami miano bitwę stoczyć spodziewano się pochodu najpóźniej na jutrzejszy ranek i były tego widome oznaki niezliczona bowiem czeladź książęca zajęta była ładowaniem na wozy broni kosztownych sprzętów i książęcego skarbca',\n",
       " '']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\" \".join(clean_line(line)) for line in load_file('./data/henryk_sienkiewicz/potop.txt')[5015:5026]] #używam czyszczenia, bo Potop był konwertowany z .mobi do .txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Słowo 'rozdział' występuje na tyle mało razy, że nie powinno zaburzyć n-gramów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00015214221859773547"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_count['rozdział']/sum(vocabulary_count.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla każdego pliku łączę całą zawartość w jeden napis i na jego podstawie tworzę n-gramy. Przykładowo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test1 test2'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([word for word in ['test1', '', '', '', 'test2'] if word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaczynam od małego pliku:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,0K\t./data/henryk_sienkiewicz/sienkiewicz-bajka.txt\n",
      "4,0K\t./data/henryk_sienkiewicz/sienkiewicz-czy-ci-najmilszy.txt\n",
      "4,0K\t./data/henryk_sienkiewicz/sienkiewicz-hkt.txt\n",
      "4,0K\t./data/henryk_sienkiewicz/sienkiewicz-przygoda-arystoklesa.txt\n",
      "4,0K\t./data/henryk_sienkiewicz/sienkiewicz-sabalowa-bajka.txt\n"
     ]
    }
   ],
   "source": [
    "! find ./data/henryk_sienkiewicz/ -type f -name '*.txt' | xargs du -h | sort -h | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(file, n):\n",
    "    # get a list of consecutive words\n",
    "    tokens = list(chain(*[clean_line(line) for line in load_file(file)]))\n",
    "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "    return [tuple(ngram) for ngram in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_example = generate_ngrams(\"./data/henryk_sienkiewicz/sienkiewicz-bajka.txt\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('henryk', 'sienkiewicz'),\n",
       " ('sienkiewicz', 'bajka'),\n",
       " ('bajka', 'za'),\n",
       " ('za', 'górami'),\n",
       " ('górami', 'za'),\n",
       " ('za', 'morzami'),\n",
       " ('morzami', 'w'),\n",
       " ('w', 'dalekiej'),\n",
       " ('dalekiej', 'krainie'),\n",
       " ('krainie', 'czarów')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_example[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter(bigrams_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('dam', 'ci'), 3),\n",
       " (('bez', 'dobroci'), 3),\n",
       " (('dobroci', 'jest'), 3),\n",
       " (('na', 'to'), 2),\n",
       " (('się', 'nad'), 2),\n",
       " (('wasze', 'dary'), 2),\n",
       " (('henryk', 'sienkiewicz'), 1),\n",
       " (('sienkiewicz', 'bajka'), 1),\n",
       " (('bajka', 'za'), 1),\n",
       " (('za', 'górami'), 1)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla każdego z autorów będę analizował n-gramy (aż do 3-gramów). Spodziewam się, że 1-gramy będą podobne (zdominowane przez partykuły, przyimki, spójniki). Wszystkie n-gramy będą trzymane w `big_n_gram_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_gram = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle Sienkiewicz's case separately\n",
    "big_n_gram_dict = dict()\n",
    "big_n_gram_dict['sienkiewicz'] = dict()\n",
    "\n",
    "# initialize big_n_gram_dict with names\n",
    "for directory in os.listdir('./data/pozytywizm/'):\n",
    "    big_n_gram_dict[directory] = dict()\n",
    "\n",
    "for filename in os.listdir('./data/henryk_sienkiewicz/'):\n",
    "    file_path = os.path.join('./data/henryk_sienkiewicz/', filename)\n",
    "    for n in range(1, max_n_gram+1):\n",
    "        try:\n",
    "            big_n_gram_dict['sienkiewicz'][\"{}_gram\".format(n)].update(Counter(generate_ngrams(file_path, n)))\n",
    "        except KeyError:\n",
    "            # handle the case in which the counter has not been initialised\n",
    "            big_n_gram_dict['sienkiewicz'][\"{}_gram\".format(n)] = Counter(generate_ngrams(file_path, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in os.listdir('./data/pozytywizm/'):\n",
    "    subdir = os.path.join('./data/pozytywizm/', directory)\n",
    "    for filename in os.listdir(subdir):\n",
    "        file_path = os.path.join(subdir, filename)\n",
    "        for n in range(1, max_n_gram+1):\n",
    "            try:\n",
    "                big_n_gram_dict[directory][\"{}_gram\".format(n)].update(Counter(generate_ngrams(file_path, n)))\n",
    "            except KeyError:\n",
    "                big_n_gram_dict[directory][\"{}_gram\".format(n)] = Counter(generate_ngrams(file_path, n))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzam najczęstsze słowa (unigramy) dla każdego z twórców i potwierdzam swoje przypuszczenia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sienkiewicz\n",
      "[(('i',), 73946), (('się',), 52173), (('w',), 45038), (('nie',), 41036), (('na',), 36392), (('z',), 33930), (('że',), 25068), (('to',), 24195), (('do',), 22870), (('a',), 22041)]\n",
      "\n",
      "Reymont\n",
      "[(('i',), 29380), (('się',), 22487), (('nie',), 14003), (('w',), 13758), (('na',), 13428), (('z',), 12117), (('a',), 11032), (('to',), 9881), (('do',), 8624), (('że',), 7680)]\n",
      "\n",
      "Konopnicka\n",
      "[(('i',), 552), (('w',), 516), (('się',), 483), (('na',), 421), (('a',), 404), (('nie',), 357), (('z',), 331), (('to',), 291), (('jak',), 246), (('do',), 212)]\n",
      "\n",
      "Prus\n",
      "[(('i',), 29038), (('się',), 26215), (('w',), 19589), (('nie',), 18922), (('na',), 17356), (('z',), 14884), (('że',), 11668), (('do',), 11571), (('a',), 10929), (('to',), 8851)]\n",
      "\n",
      "Zeromski\n",
      "[(('i',), 24556), (('w',), 23065), (('się',), 17777), (('na',), 14639), (('z',), 14349), (('nie',), 10604), (('do',), 8493), (('to',), 7159), (('a',), 5789), (('jak',), 5130)]\n",
      "\n",
      "Balucki\n",
      "[(('i',), 2605), (('się',), 2431), (('w',), 1566), (('nie',), 1526), (('na',), 1438), (('z',), 1382), (('do',), 1125), (('to',), 1120), (('że',), 962), (('a',), 827)]\n",
      "\n",
      "Orzeszkowa\n",
      "[(('i',), 54481), (('w',), 31658), (('się',), 29054), (('z',), 24561), (('na',), 21473), (('nie',), 20026), (('do',), 12668), (('a',), 12089), (('to',), 11141), (('że',), 9541)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for writer in ['sienkiewicz'] + [directory for directory in os.listdir(\"./data/pozytywizm/\")]:\n",
    "    print(writer.capitalize())\n",
    "    print(big_n_gram_dict[writer]['1_gram'].most_common(10))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzam 2-gramy. Ciekawe jest to, że w 2-gramach dla Sienkiewicza i Reymonta zawarte są informacje o przypisach, np *2509. zo­sta­wu­jem — dziś popr. for­ma 1.os. lm cz.ter.: zo­sta­wia­my. [przypis edytorski]* Sam Potop ma ich 2514:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sienkiewicz\n",
      "[(('przypis', 'edytorski'), 5973), (('przypis', 'redakcyjny'), 3730), (('się', 'w'), 3010), (('się', 'z'), 2472), (('się', 'na'), 2390), (('się', 'do'), 2176), (('i', 'nie'), 1664), (('i', 'w'), 1565), (('się', 'i'), 1384), (('mu', 'się'), 1367)]\n",
      "\n",
      "Reymont\n",
      "[(('przypis', 'edytorski'), 3553), (('się', 'z'), 1081), (('się', 'w'), 1030), (('się', 'na'), 823), (('się', 'do'), 789), (('i', 'z'), 626), (('się', 'nie'), 616), (('i', 'nie'), 587), (('i', 'tak'), 560), (('daw', 'gw'), 543)]\n",
      "\n",
      "Konopnicka\n",
      "[(('i', 'na'), 24), (('a', 'to'), 24), (('się', 'z'), 21), (('jak', 'się'), 20), (('a', 'ty'), 20), (('der', 'der'), 20), (('pan', 'łukasz'), 19), (('raz', 'dwa'), 17), (('dwa', 'trzy'), 17), (('a', 'ja'), 16)]\n",
      "\n",
      "Prus\n",
      "[(('się', 'z'), 1513), (('się', 'w'), 1485), (('się', 'do'), 1364), (('się', 'na'), 1337), (('się', 'że'), 1054), (('przypis', 'redakcyjny'), 912), (('się', 'i'), 888), (('w', 'tej'), 815), (('pani', 'latter'), 708), (('mu', 'się'), 668)]\n",
      "\n",
      "Zeromski\n",
      "[(('się', 'w'), 1698), (('się', 'z'), 1032), (('się', 'na'), 947), (('się', 'do'), 745), (('się', 'i'), 625), (('w', 'tym'), 520), (('i', 'w'), 490), (('i', 'z'), 405), (('i', 'nie'), 401), (('nie', 'ma'), 388)]\n",
      "\n",
      "Balucki\n",
      "[(('się', 'do'), 123), (('się', 'w'), 116), (('się', 'z'), 114), (('się', 'na'), 108), (('mu', 'się'), 80), (('się', 'że'), 67), (('się', 'o'), 58), (('do', 'tego'), 58), (('pani', 'radczyni'), 58), (('i', 'nie'), 56)]\n",
      "\n",
      "Orzeszkowa\n",
      "[(('się', 'w'), 1956), (('się', 'z'), 1625), (('się', 'i'), 1336), (('się', 'na'), 1243), (('i', 'z'), 1219), (('i', 'w'), 1172), (('się', 'do'), 852), (('i', 'nie'), 829), (('i', 'na'), 769), (('w', 'tym'), 659)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for writer in ['sienkiewicz'] + [directory for directory in os.listdir(\"./data/pozytywizm/\")]:\n",
    "    print(writer.capitalize())\n",
    "    print(big_n_gram_dict[writer]['2_gram'].most_common(10))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przypisy edytorskie i redakcyjne odciskają piętno także na 3-gramach. Warto zwrócić uwagę na *w tej chwili* oraz *w ten sposób*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sienkiewicz\n",
      "[(('w', 'tej', 'chwili'), 723), (('zwrócił', 'się', 'do'), 320), (('w', 'ten', 'sposób'), 292), (('się', 'z', 'nim'), 232), (('dziś', 'popr', 'forma'), 224), (('w', 'takim', 'razie'), 216), (('wasza', 'książęca', 'mość'), 215), (('nie', 'może', 'być'), 214), (('ok', 'km', 'na'), 214), (('od', 'czasu', 'do'), 203)]\n",
      "\n",
      "Reymont\n",
      "[(('przypis', 'edytorski', 'kiej'), 218), (('edytorski', 'kiej', 'gw'), 206), (('tylko', 'przypis', 'edytorski'), 175), (('gw', 'tylko', 'przypis'), 173), (('przypis', 'edytorski', 'jeno'), 170), (('jeno', 'daw', 'gw'), 160), (('edytorski', 'jeno', 'daw'), 159), (('daw', 'gw', 'tylko'), 159), (('jak', 'przypis', 'edytorski'), 156), (('aż', 'przypis', 'edytorski'), 131)]\n",
      "\n",
      "Konopnicka\n",
      "[(('raz', 'dwa', 'trzy'), 17), (('der', 'der', 'der'), 16), (('kle', 'kle', 'kle'), 12), (('wielki', 'pustak', 'nasza'), 9), (('pustak', 'nasza', 'hania'), 9), (('la', 'la', 'la'), 8), (('pi', 'pi', 'pi'), 8), (('raz', 'i', 'drugi'), 7), (('nasza', 'zima', 'zła'), 6), (('a', 'gońże', 'nas'), 6)]\n",
      "\n",
      "Prus\n",
      "[(('w', 'tej', 'chwili'), 613), (('mu', 'się', 'że'), 190), (('zdawało', 'mu', 'się'), 171), (('mi', 'się', 'że'), 164), (('zdaje', 'mi', 'się'), 148), (('w', 'takim', 'razie'), 135), (('a', 'nade', 'wszystko'), 122), (('zdawało', 'się', 'że'), 121), (('na', 'drugi', 'dzień'), 103), (('cóż', 'to', 'za'), 101)]\n",
      "\n",
      "Zeromski\n",
      "[(('w', 'tej', 'chwili'), 95), (('w', 'pewnej', 'chwili'), 84), (('tak', 'samo', 'jak'), 71), (('w', 'tym', 'miejscu'), 70), (('zdawało', 'się', 'że'), 68), (('mu', 'się', 'że'), 62), (('w', 'tej', 'samej'), 60), (('się', 'w', 'nim'), 56), (('zbliżył', 'się', 'do'), 56), (('tam', 'i', 'sam'), 54)]\n",
      "\n",
      "Balucki\n",
      "[(('w', 'ten', 'sposób'), 20), (('w', 'tej', 'chwili'), 17), (('na', 'drugi', 'dzień'), 15), (('się', 'do', 'niego'), 14), (('się', 'do', 'tego'), 11), (('się', 'z', 'nią'), 11), (('z', 'tego', 'powodu'), 11), (('ze', 'względu', 'na'), 10), (('co', 'to', 'za'), 10), (('nie', 'bój', 'się'), 8)]\n",
      "\n",
      "Orzeszkowa\n",
      "[(('w', 'tej', 'chwili'), 295), (('co', 'tu', 'robić'), 169), (('po', 'raz', 'pierwszy'), 140), (('w', 'ten', 'sposób'), 102), (('za', 'to', 'że'), 85), (('się', 'w', 'nim'), 77), (('zdaje', 'się', 'że'), 75), (('cha', 'cha', 'cha'), 75), (('tu', 'i', 'ówdzie'), 74), (('tu', 'i', 'owdzie'), 73)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for writer in ['sienkiewicz'] + [directory for directory in os.listdir(\"./data/pozytywizm/\")]:\n",
    "    print(writer.capitalize())\n",
    "    print(big_n_gram_dict[writer]['3_gram'].most_common(10))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co jeżeli wykluczę przypisy i partykuły? Poniższy przykład bardzo dobrze ilustruje jak bardzo stopwords mogą zanieczyścić listę n-gramów. Na 100 pierwszych 2-gramów jedynie mała część pozostaje po wyeliminowaniu tych, w której występuje co najmniej jeden stopword (`zakazane_slowa`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "zakazane_slowa = set(['przypis', 'redakcyjny', 'edytorski', 'w', 'z', 'i', 'o', 'nie', 'się', 'do', 'że', 'to', 'po', 'a', 'dla', 'tak', 'na'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('pan', 'zagłoba'), 816),\n",
       " (('tej', 'chwili'), 775),\n",
       " (('dziś', 'popr'), 535),\n",
       " (('przy', 'tym'), 474),\n",
       " (('pan', 'wołodyjowski'), 471),\n",
       " (('może', 'być'), 469)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n_gram for n_gram in big_n_gram_dict['sienkiewicz']['2_gram'].most_common(100) if not set(n_gram[0]).intersection(zakazane_slowa)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podobny zabieg, ale zastosowany do 3-gramów pokazuje, że dane nie zostały do końca dobrze wyczyszczone, ponieważ częstymi trzygramami są słowa odnoszące się do licencji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('dziś', 'popr', 'forma'), 224),\n",
       " (('wasza', 'książęca', 'mość'), 215),\n",
       " (('przez', 'ten', 'czas'), 109),\n",
       " (('nastała', 'chwila', 'milczenia'), 109),\n",
       " (('waszej', 'książęcej', 'mości'), 101),\n",
       " (('rezydencja', 'książąt', 'wiśniowieckich'), 90),\n",
       " (('ukrainy', 'ok', 'km'), 89),\n",
       " (('jak', 'mi', 'bóg'), 87),\n",
       " (('mi', 'bóg', 'miły'), 86),\n",
       " (('części', 'ukrainy', 'ok'), 84),\n",
       " (('wielki', 'książę', 'litewski'), 82),\n",
       " (('śrwsch', 'ukrainie', 'rezydencja'), 79),\n",
       " (('ukrainie', 'rezydencja', 'książąt'), 79),\n",
       " (('jeno', 'daw', 'tylko'), 77),\n",
       " (('tekst', 'jest', 'własnością'), 77),\n",
       " (('jest', 'własnością', 'publiczną'), 77),\n",
       " (('własnością', 'publiczną', 'public'), 77),\n",
       " (('publiczną', 'public', 'domain'), 77),\n",
       " (('public', 'domain', 'szczegóły'), 77),\n",
       " (('domain', 'szczegóły', 'licencji'), 77)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n_gram for n_gram in big_n_gram_dict['sienkiewicz']['3_gram'].most_common(100) if not set(n_gram[0]).intersection(zakazane_slowa)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widzimy, że w 2-gramach i 3-gramach bez udziału stopwords mamy do czynienia także z informacjami przypisowymi (daw jako dawniej, gw jako gwarowo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('daw', 'gw'), 543),\n",
       " (('co', 'chwila'), 217),\n",
       " (('za', 'nim'), 217),\n",
       " (('kiej', 'gw'), 206),\n",
       " (('gw', 'tylko'), 183),\n",
       " (('za', 'nią'), 160),\n",
       " (('jeno', 'daw'), 160)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n_gram for n_gram in big_n_gram_dict['reymont']['2_gram'].most_common(100) if not set(n_gram[0]).intersection(zakazane_slowa)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('jeno', 'daw', 'gw'), 160),\n",
       " (('daw', 'gw', 'tylko'), 159),\n",
       " (('jaże', 'gw', 'aż'), 127),\n",
       " (('kiej', 'gw', 'jak'), 118),\n",
       " (('kieby', 'gw', 'niby'), 65),\n",
       " (('kajś', 'gw', 'gdzieś'), 63),\n",
       " (('kiej', 'gw', 'kiedy'), 61),\n",
       " (('gw', 'niby', 'jak'), 59),\n",
       " (('ze', 'wszystkich', 'stron'), 58),\n",
       " (('cosik', 'gw', 'coś'), 58),\n",
       " (('kaj', 'gw', 'gdzie'), 55),\n",
       " (('me', 'gw', 'mnie'), 54),\n",
       " (('boga', 'tego', 'kocham'), 51),\n",
       " (('jak', 'boga', 'tego'), 49),\n",
       " (('cięgiem', 'gw', 'ciągle'), 40),\n",
       " (('jąć', 'daw', 'gw'), 39),\n",
       " (('daw', 'gw', 'zacząć'), 39),\n",
       " (('se', 'gw', 'sobie'), 38),\n",
       " (('ha', 'ha', 'ha'), 36)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n_gram for n_gram in big_n_gram_dict['reymont']['3_gram'].most_common(100) if not set(n_gram[0]).intersection(zakazane_slowa)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do stopwords dodaję wyjątki dla informacji przypisowych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "zakazane_slowa = zakazane_slowa.union(set(['gw', 'daw']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla Reymonta widzimy akcję umiejscowioną na wsi (bigram *we wsi*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('co', 'chwila'), 217),\n",
       " (('za', 'nim'), 217),\n",
       " (('za', 'nią'), 160),\n",
       " (('pan', 'jezus'), 138),\n",
       " (('ale', 'już'), 129),\n",
       " (('bo', 'już'), 117),\n",
       " (('we', 'wsi'), 115),\n",
       " (('przy', 'tym'), 115),\n",
       " (('ze', 'wszystkich'), 113),\n",
       " (('tej', 'chwili'), 104),\n",
       " (('u', 'nas'), 104),\n",
       " (('przed', 'nim'), 95)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n_gram for n_gram in big_n_gram_dict['reymont']['2_gram'].most_common(200) if not set(n_gram[0]).intersection(zakazane_slowa)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oraz religijność bohaterów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ze', 'wszystkich', 'stron'), 58),\n",
       " (('boga', 'tego', 'kocham'), 51),\n",
       " (('jak', 'boga', 'tego'), 49),\n",
       " (('ha', 'ha', 'ha'), 36),\n",
       " (('psiakość', 'nóżki', 'baranie'), 30),\n",
       " (('dobrodzieju', 'mój', 'kochany'), 26),\n",
       " (('jak', 'ten', 'pies'), 23)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n_gram for n_gram in big_n_gram_dict['reymont']['3_gram'].most_common(200) if not set(n_gram[0]).intersection(zakazane_slowa)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "zakazane_slowa = zakazane_slowa.union(set(['kto', 'przez', 'co']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U Orzeszkowej także widać religijność bohaterów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('tej', 'chwili'), 302),\n",
       " (('widać', 'było'), 202),\n",
       " (('przed', 'nim'), 177),\n",
       " (('pan', 'bóg'), 175),\n",
       " (('tu', 'robić'), 174),\n",
       " (('ku', 'niemu'), 173),\n",
       " (('tym', 'razem'), 170),\n",
       " (('za', 'nią'), 166),\n",
       " (('można', 'było'), 163),\n",
       " (('przed', 'nią'), 161),\n",
       " (('raz', 'pierwszy'), 143),\n",
       " (('może', 'być'), 142)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n_gram for n_gram in big_n_gram_dict['orzeszkowa']['2_gram'].most_common(200) if not set(n_gram[0]).intersection(zakazane_slowa)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('cha', 'cha', 'cha'), 75),\n",
       " (('ach', 'ach', 'ach'), 45),\n",
       " (('jak', 'boga', 'kocham'), 44),\n",
       " (('czy', 'ja', 'wiem'), 36),\n",
       " (('tej', 'samej', 'chwili'), 35),\n",
       " (('panie', 'mój', 'kochany'), 33),\n",
       " (('pod', 'tym', 'względem'), 31),\n",
       " (('od', 'tego', 'czasu'), 23),\n",
       " (('poznać', 'można', 'było'), 22),\n",
       " (('boże', 'mój', 'boże'), 21),\n",
       " (('kilka', 'kroków', 'od'), 21),\n",
       " (('ha', 'ha', 'ha'), 21)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n_gram for n_gram in big_n_gram_dict['orzeszkowa']['3_gram'].most_common(200) if not set(n_gram[0]).intersection(zakazane_slowa)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U Prusa zauważalni są nazwami bohaterowie: *Panna Latter* (Emancypatka), *Panna Izabela*/*Panny Izabeli* (Lalka), *Panna Howard* (Emancypatka), *Pan Tomasz* (Katarynka):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('pani', 'latter'), 708),\n",
       " (('tej', 'chwili'), 645),\n",
       " (('panna', 'izabela'), 452),\n",
       " (('pan', 'kazimierz'), 252),\n",
       " (('tysięcy', 'rubli'), 249),\n",
       " (('panna', 'howard'), 230),\n",
       " (('pan', 'ignacy'), 197),\n",
       " (('może', 'być'), 190),\n",
       " (('u', 'nas'), 189),\n",
       " (('za', 'rękę'), 187),\n",
       " (('ze', 'mną'), 184),\n",
       " (('zdawało', 'mu'), 171),\n",
       " (('pan', 'tomasz'), 162),\n",
       " (('nade', 'wszystko'), 160),\n",
       " (('go', 'za'), 159),\n",
       " (('przede', 'wszystkim'), 154),\n",
       " (('musi', 'być'), 150),\n",
       " (('za', 'nim'), 148),\n",
       " (('zdaje', 'mi'), 148),\n",
       " (('od', 'tej'), 143),\n",
       " (('ale', 'ja'), 142),\n",
       " (('kilka', 'dni'), 139),\n",
       " (('od', 'razu'), 138),\n",
       " (('wasza', 'dostojność'), 136),\n",
       " (('takim', 'razie'), 135),\n",
       " (('panny', 'izabeli'), 133),\n",
       " (('jego', 'świątobliwości'), 133),\n",
       " (('można', 'było'), 131),\n",
       " (('przy', 'tym'), 129)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n_gram for n_gram in big_n_gram_dict['prus']['2_gram'].most_common(200) if not set(n_gram[0]).intersection(zakazane_slowa)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miejsce akcji Faraona (*Dolny Egipt*), który był podzielony na 20 *nomów*([nomy](https://pl.wikipedia.org/wiki/Dolny_Egipt#/media/File:GD-EG-Nomes_de_Basse-%C3%89gypte.jpg)) oraz jednostka monetarna zaboru rosyjskiego (rubel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('od', 'tej', 'pory'), 93),\n",
       " (('go', 'za', 'rękę'), 55),\n",
       " (('ją', 'za', 'rękę'), 54),\n",
       " (('czy', 'ja', 'wiem'), 50),\n",
       " (('cha', 'cha', 'cha'), 41),\n",
       " (('ze', 'wszystkich', 'stron'), 38),\n",
       " (('od', 'kilku', 'dni'), 33),\n",
       " (('od', 'tej', 'chwili'), 29),\n",
       " (('oby', 'żył', 'wiecznie'), 27),\n",
       " (('cztery', 'tysiące', 'rubli'), 24),\n",
       " (('od', 'pewnego', 'czasu'), 24),\n",
       " (('dziesięć', 'tysięcy', 'rubli'), 24),\n",
       " (('trzydzieści', 'tysięcy', 'rubli'), 23),\n",
       " (('nomu', 'dolnego', 'egiptu'), 23),\n",
       " (('tej', 'samej', 'chwili'), 22)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n_gram for n_gram in big_n_gram_dict['prus']['3_gram'].most_common(200) if not set(n_gram[0]).intersection(zakazane_slowa)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W poniższej części zajmuję się tworzeniem reprezentacji wektorowych słów w analizowym korpusie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celem zwiększenia szybkości wykonywanych obliczeń stosuję:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzę listę list, gdzie zagnieżdżona lista zawiera słowa składające się na poszczególne zdania:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_toy_data = [clean_line(line) for line in load_file('./data/henryk_sienkiewicz/potop.txt')[5015:5026] if line != '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jakże',\n",
       " 'nie',\n",
       " 'wiem',\n",
       " 'odparł',\n",
       " 'szlachcic',\n",
       " 'to',\n",
       " 'pan',\n",
       " 'tomasz',\n",
       " 'billewicz',\n",
       " 'miecznik',\n",
       " 'rosieński',\n",
       " 'wszyscy',\n",
       " 'go',\n",
       " 'tu',\n",
       " 'znają',\n",
       " 'bo',\n",
       " 'to',\n",
       " 'dawny',\n",
       " 'radziwiłłowski',\n",
       " 'sługa',\n",
       " 'i',\n",
       " 'przyjaciel']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_toy_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('./data/henryk_sienkiewicz/'):\n",
    "    file_path = os.path.join('./data/henryk_sienkiewicz/', filename)\n",
    "    sentences += [clean_line(line) for line in load_file(file_path) if line != '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in os.listdir('./data/pozytywizm/'):\n",
    "    subdir = os.path.join('./data/pozytywizm/', directory)\n",
    "    for filename in os.listdir(subdir):\n",
    "        file_path = os.path.join(subdir, filename)\n",
    "        sentences += [clean_line(line) for line in load_file(file_path) if line != '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236529"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiuję parametry modelu:\n",
    " - `min_count`: ignoruje słowa, które występują rzadziej niż zadana liczba razy\n",
    " - `window`: jaka odległość w zdaniu dzieli obecnie analizowane słowo (input do sieci) od przewidywanego (output z sieci)\n",
    " - `size`: wymiar wektora zanurzonego\n",
    " - `workers`: liczba rdzeni do obsługi trenowania modelu\n",
    " - `seed`: ziarno, które zapewnia replikowalność"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:45:46: collecting all words and their counts\n",
      "INFO - 18:45:46: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 18:45:46: PROGRESS: at sentence #10000, processed 310875 words, keeping 40921 word types\n",
      "INFO - 18:45:46: PROGRESS: at sentence #20000, processed 565984 words, keeping 58780 word types\n",
      "INFO - 18:45:46: PROGRESS: at sentence #30000, processed 911598 words, keeping 77806 word types\n",
      "INFO - 18:45:46: PROGRESS: at sentence #40000, processed 1238606 words, keeping 93103 word types\n",
      "INFO - 18:45:46: PROGRESS: at sentence #50000, processed 1528328 words, keeping 105237 word types\n",
      "INFO - 18:45:46: PROGRESS: at sentence #60000, processed 1764294 words, keeping 112687 word types\n",
      "INFO - 18:45:46: PROGRESS: at sentence #70000, processed 1980724 words, keeping 120420 word types\n",
      "INFO - 18:45:46: PROGRESS: at sentence #80000, processed 2248307 words, keeping 132726 word types\n",
      "INFO - 18:45:46: PROGRESS: at sentence #90000, processed 2494371 words, keeping 144397 word types\n",
      "INFO - 18:45:46: PROGRESS: at sentence #100000, processed 2650792 words, keeping 150613 word types\n",
      "INFO - 18:45:46: PROGRESS: at sentence #110000, processed 2807101 words, keeping 156396 word types\n",
      "INFO - 18:45:46: PROGRESS: at sentence #120000, processed 3023147 words, keeping 162936 word types\n",
      "INFO - 18:45:46: PROGRESS: at sentence #130000, processed 3227063 words, keeping 168983 word types\n",
      "INFO - 18:45:46: PROGRESS: at sentence #140000, processed 3453835 words, keeping 174925 word types\n",
      "INFO - 18:45:46: PROGRESS: at sentence #150000, processed 3670478 words, keeping 180774 word types\n",
      "INFO - 18:45:46: PROGRESS: at sentence #160000, processed 3769277 words, keeping 183497 word types\n",
      "INFO - 18:45:47: PROGRESS: at sentence #170000, processed 3943207 words, keeping 191900 word types\n",
      "INFO - 18:45:47: PROGRESS: at sentence #180000, processed 4306960 words, keeping 210099 word types\n",
      "INFO - 18:45:47: PROGRESS: at sentence #190000, processed 4511839 words, keeping 217103 word types\n",
      "INFO - 18:45:47: PROGRESS: at sentence #200000, processed 4615304 words, keeping 220580 word types\n",
      "INFO - 18:45:47: PROGRESS: at sentence #210000, processed 5020066 words, keeping 234916 word types\n",
      "INFO - 18:45:47: PROGRESS: at sentence #220000, processed 5318383 words, keeping 246119 word types\n",
      "INFO - 18:45:47: PROGRESS: at sentence #230000, processed 5630056 words, keeping 256383 word types\n",
      "INFO - 18:45:47: collected 262178 word types from a corpus of 5876081 raw words and 236529 sentences\n",
      "INFO - 18:45:47: Loading a fresh vocabulary\n",
      "INFO - 18:45:47: effective_min_count=5 retains 76645 unique words (29% of original 262178, drops 185533)\n",
      "INFO - 18:45:47: effective_min_count=5 leaves 5566554 word corpus (94% of original 5876081, drops 309527)\n",
      "INFO - 18:45:48: deleting the raw counts dictionary of 262178 items\n",
      "INFO - 18:45:48: sample=0.001 downsamples 30 most-common words\n",
      "INFO - 18:45:48: downsampling leaves estimated 4680643 word corpus (84.1% of prior 5566554)\n",
      "INFO - 18:45:48: estimated required memory for 76645 words and 100 dimensions: 99638500 bytes\n",
      "INFO - 18:45:48: resetting layer weights\n",
      "INFO - 18:45:48: training model with 6 workers on 76645 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 18:45:49: EPOCH 1 - PROGRESS: at 25.45% examples, 1409648 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:45:50: EPOCH 1 - PROGRESS: at 60.80% examples, 1404890 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:45:51: EPOCH 1 - PROGRESS: at 92.59% examples, 1396306 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:45:52: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:45:52: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:45:52: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:45:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:45:52: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:45:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:45:52: EPOCH - 1 : training on 5876081 raw words (4680127 effective words) took 3.3s, 1400962 effective words/s\n",
      "INFO - 18:45:53: EPOCH 2 - PROGRESS: at 27.35% examples, 1491871 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:45:54: EPOCH 2 - PROGRESS: at 62.55% examples, 1444334 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:45:55: EPOCH 2 - PROGRESS: at 94.03% examples, 1414626 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:45:55: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:45:55: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:45:55: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:45:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:45:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:45:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:45:55: EPOCH - 2 : training on 5876081 raw words (4680022 effective words) took 3.3s, 1417780 effective words/s\n",
      "INFO - 18:45:56: EPOCH 3 - PROGRESS: at 27.35% examples, 1486158 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:45:57: EPOCH 3 - PROGRESS: at 62.40% examples, 1438660 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:45:58: EPOCH 3 - PROGRESS: at 94.96% examples, 1428412 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:45:58: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:45:58: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:45:58: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:45:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:45:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:45:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:45:58: EPOCH - 3 : training on 5876081 raw words (4680224 effective words) took 3.3s, 1431798 effective words/s\n",
      "INFO - 18:45:59: EPOCH 4 - PROGRESS: at 27.94% examples, 1504764 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:46:00: EPOCH 4 - PROGRESS: at 62.18% examples, 1441559 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:46:01: EPOCH 4 - PROGRESS: at 92.32% examples, 1399240 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:46:02: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:46:02: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:46:02: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:46:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:46:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:46:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:46:02: EPOCH - 4 : training on 5876081 raw words (4681159 effective words) took 3.4s, 1394190 effective words/s\n",
      "INFO - 18:46:03: EPOCH 5 - PROGRESS: at 25.36% examples, 1420596 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:46:04: EPOCH 5 - PROGRESS: at 59.26% examples, 1387296 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:46:05: EPOCH 5 - PROGRESS: at 89.37% examples, 1350595 words/s, in_qsize 11, out_qsize 1\n",
      "INFO - 18:46:05: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:46:05: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:46:05: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:46:05: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:46:05: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:46:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:46:05: EPOCH - 5 : training on 5876081 raw words (4681203 effective words) took 3.5s, 1354153 effective words/s\n",
      "INFO - 18:46:05: training on a 29380405 raw words (23402735 effective words) took 16.8s, 1395864 effective words/s\n"
     ]
    }
   ],
   "source": [
    "w2v_pozytywizm = Word2Vec(sentences, size=100, window=5, min_count=5, workers=cores-2, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 18:48:24: Effective 'alpha' higher than previous training cycles\n",
      "INFO - 18:48:24: training model with 6 workers on 76645 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 18:48:25: EPOCH 1 - PROGRESS: at 25.45% examples, 1422472 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:48:26: EPOCH 1 - PROGRESS: at 60.01% examples, 1400295 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:48:27: EPOCH 1 - PROGRESS: at 91.17% examples, 1385729 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:48:27: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:48:27: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:48:27: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:48:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:48:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:48:27: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:48:27: EPOCH - 1 : training on 5876081 raw words (4681178 effective words) took 3.4s, 1387067 effective words/s\n",
      "INFO - 18:48:28: EPOCH 2 - PROGRESS: at 25.61% examples, 1424910 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:48:29: EPOCH 2 - PROGRESS: at 60.23% examples, 1397182 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:48:30: EPOCH 2 - PROGRESS: at 91.05% examples, 1378076 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:48:30: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:48:30: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:48:30: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:48:30: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:48:30: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:48:30: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:48:30: EPOCH - 2 : training on 5876081 raw words (4680991 effective words) took 3.4s, 1385178 effective words/s\n",
      "INFO - 18:48:31: EPOCH 3 - PROGRESS: at 25.33% examples, 1414983 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:48:32: EPOCH 3 - PROGRESS: at 60.23% examples, 1401459 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:48:33: EPOCH 3 - PROGRESS: at 91.39% examples, 1386147 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:48:34: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:48:34: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:48:34: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:48:34: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:48:34: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:48:34: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:48:34: EPOCH - 3 : training on 5876081 raw words (4680916 effective words) took 3.4s, 1391079 effective words/s\n",
      "INFO - 18:48:35: EPOCH 4 - PROGRESS: at 25.85% examples, 1448536 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:48:36: EPOCH 4 - PROGRESS: at 59.61% examples, 1392626 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:48:37: EPOCH 4 - PROGRESS: at 90.51% examples, 1368796 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:48:37: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:48:37: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:48:37: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:48:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:48:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:48:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:48:37: EPOCH - 4 : training on 5876081 raw words (4680583 effective words) took 3.4s, 1357356 effective words/s\n",
      "INFO - 18:48:38: EPOCH 5 - PROGRESS: at 25.05% examples, 1382716 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:48:39: EPOCH 5 - PROGRESS: at 58.14% examples, 1350162 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:48:40: EPOCH 5 - PROGRESS: at 89.01% examples, 1334815 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:48:41: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:48:41: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:48:41: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:48:41: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:48:41: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:48:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:48:41: EPOCH - 5 : training on 5876081 raw words (4681180 effective words) took 3.6s, 1311466 effective words/s\n",
      "INFO - 18:48:42: EPOCH 6 - PROGRESS: at 24.34% examples, 1342862 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:48:43: EPOCH 6 - PROGRESS: at 58.17% examples, 1349356 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:48:44: EPOCH 6 - PROGRESS: at 89.27% examples, 1340811 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:48:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:48:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:48:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:48:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:48:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:48:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:48:44: EPOCH - 6 : training on 5876081 raw words (4680463 effective words) took 3.5s, 1334849 effective words/s\n",
      "INFO - 18:48:45: EPOCH 7 - PROGRESS: at 23.53% examples, 1325127 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:48:46: EPOCH 7 - PROGRESS: at 52.54% examples, 1250335 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:48:47: EPOCH 7 - PROGRESS: at 84.99% examples, 1248803 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:48:48: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:48:48: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:48:48: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:48:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:48:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:48:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:48:48: EPOCH - 7 : training on 5876081 raw words (4681384 effective words) took 3.7s, 1256930 effective words/s\n",
      "INFO - 18:48:49: EPOCH 8 - PROGRESS: at 24.34% examples, 1351124 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:48:50: EPOCH 8 - PROGRESS: at 56.69% examples, 1319392 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:48:51: EPOCH 8 - PROGRESS: at 86.84% examples, 1288939 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:48:52: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:48:52: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:48:52: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:48:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:48:52: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:48:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:48:52: EPOCH - 8 : training on 5876081 raw words (4681137 effective words) took 3.6s, 1301092 effective words/s\n",
      "INFO - 18:48:53: EPOCH 9 - PROGRESS: at 21.07% examples, 1216795 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:48:54: EPOCH 9 - PROGRESS: at 53.89% examples, 1264143 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:48:55: EPOCH 9 - PROGRESS: at 85.87% examples, 1261184 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:48:55: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:48:55: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:48:55: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:48:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:48:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:48:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:48:55: EPOCH - 9 : training on 5876081 raw words (4680623 effective words) took 3.7s, 1254392 effective words/s\n",
      "INFO - 18:48:56: EPOCH 10 - PROGRESS: at 23.53% examples, 1319052 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:48:58: EPOCH 10 - PROGRESS: at 57.08% examples, 1325539 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:48:59: EPOCH 10 - PROGRESS: at 88.62% examples, 1317540 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:48:59: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:48:59: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:48:59: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:48:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:48:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:48:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:48:59: EPOCH - 10 : training on 5876081 raw words (4681373 effective words) took 3.5s, 1320489 effective words/s\n",
      "INFO - 18:49:00: EPOCH 11 - PROGRESS: at 24.36% examples, 1358497 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:49:01: EPOCH 11 - PROGRESS: at 56.19% examples, 1311593 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:02: EPOCH 11 - PROGRESS: at 87.53% examples, 1308125 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:49:03: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:03: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:03: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:03: EPOCH - 11 : training on 5876081 raw words (4680052 effective words) took 3.6s, 1306928 effective words/s\n",
      "INFO - 18:49:04: EPOCH 12 - PROGRESS: at 24.66% examples, 1363328 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:49:05: EPOCH 12 - PROGRESS: at 56.73% examples, 1321845 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:49:06: EPOCH 12 - PROGRESS: at 88.22% examples, 1317069 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:49:06: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:06: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:06: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:06: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:06: EPOCH - 12 : training on 5876081 raw words (4680196 effective words) took 3.5s, 1319231 effective words/s\n",
      "INFO - 18:49:07: EPOCH 13 - PROGRESS: at 25.49% examples, 1416779 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:08: EPOCH 13 - PROGRESS: at 59.08% examples, 1375783 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:49:09: EPOCH 13 - PROGRESS: at 88.76% examples, 1328463 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:10: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:10: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:10: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:10: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:10: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:10: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:10: EPOCH - 13 : training on 5876081 raw words (4680668 effective words) took 3.5s, 1319794 effective words/s\n",
      "INFO - 18:49:11: EPOCH 14 - PROGRESS: at 25.20% examples, 1408298 words/s, in_qsize 12, out_qsize 2\n",
      "INFO - 18:49:12: EPOCH 14 - PROGRESS: at 59.81% examples, 1391686 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:49:13: EPOCH 14 - PROGRESS: at 90.79% examples, 1369054 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:13: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:13: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:13: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:13: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:13: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:13: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:13: EPOCH - 14 : training on 5876081 raw words (4680681 effective words) took 3.4s, 1366120 effective words/s\n",
      "INFO - 18:49:14: EPOCH 15 - PROGRESS: at 25.72% examples, 1434937 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:49:15: EPOCH 15 - PROGRESS: at 60.01% examples, 1394464 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:49:16: EPOCH 15 - PROGRESS: at 90.51% examples, 1367667 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:17: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:17: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:17: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:17: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:17: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:17: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:17: EPOCH - 15 : training on 5876081 raw words (4680441 effective words) took 3.4s, 1361898 effective words/s\n",
      "INFO - 18:49:18: EPOCH 16 - PROGRESS: at 25.18% examples, 1411642 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:49:19: EPOCH 16 - PROGRESS: at 59.45% examples, 1385504 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:49:20: EPOCH 16 - PROGRESS: at 89.27% examples, 1346423 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:49:20: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:20: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:20: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:20: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:20: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:20: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:20: EPOCH - 16 : training on 5876081 raw words (4680706 effective words) took 3.5s, 1350659 effective words/s\n",
      "INFO - 18:49:21: EPOCH 17 - PROGRESS: at 25.60% examples, 1434813 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:22: EPOCH 17 - PROGRESS: at 59.81% examples, 1395417 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:49:23: EPOCH 17 - PROGRESS: at 89.29% examples, 1347105 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:49:24: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:24: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:24: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:24: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:24: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:24: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:24: EPOCH - 17 : training on 5876081 raw words (4680907 effective words) took 3.5s, 1329975 effective words/s\n",
      "INFO - 18:49:25: EPOCH 18 - PROGRESS: at 23.24% examples, 1305976 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:26: EPOCH 18 - PROGRESS: at 55.41% examples, 1300112 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:27: EPOCH 18 - PROGRESS: at 85.87% examples, 1265632 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:49:27: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:27: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:27: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:27: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:27: EPOCH - 18 : training on 5876081 raw words (4680581 effective words) took 3.7s, 1279600 effective words/s\n",
      "INFO - 18:49:28: EPOCH 19 - PROGRESS: at 23.85% examples, 1331881 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:49:29: EPOCH 19 - PROGRESS: at 57.65% examples, 1344002 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:49:30: EPOCH 19 - PROGRESS: at 87.66% examples, 1312107 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:49:31: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:31: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:31: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:31: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:31: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:31: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:31: EPOCH - 19 : training on 5876081 raw words (4680021 effective words) took 3.6s, 1309195 effective words/s\n",
      "INFO - 18:49:32: EPOCH 20 - PROGRESS: at 25.49% examples, 1427715 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:33: EPOCH 20 - PROGRESS: at 59.45% examples, 1390434 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:34: EPOCH 20 - PROGRESS: at 90.10% examples, 1365521 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:49:34: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:34: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:34: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:34: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:34: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:34: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:34: EPOCH - 20 : training on 5876081 raw words (4680191 effective words) took 3.4s, 1368282 effective words/s\n",
      "INFO - 18:49:35: EPOCH 21 - PROGRESS: at 23.27% examples, 1295375 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:36: EPOCH 21 - PROGRESS: at 57.24% examples, 1332495 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:49:37: EPOCH 21 - PROGRESS: at 89.10% examples, 1330334 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:49:38: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:38: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:38: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:38: EPOCH - 21 : training on 5876081 raw words (4680463 effective words) took 3.5s, 1346427 effective words/s\n",
      "INFO - 18:49:39: EPOCH 22 - PROGRESS: at 24.52% examples, 1361941 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:49:40: EPOCH 22 - PROGRESS: at 58.33% examples, 1357295 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:41: EPOCH 22 - PROGRESS: at 88.76% examples, 1326917 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:49:41: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:41: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:41: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:41: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:41: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:41: EPOCH - 22 : training on 5876081 raw words (4679909 effective words) took 3.5s, 1335905 effective words/s\n",
      "INFO - 18:49:42: EPOCH 23 - PROGRESS: at 25.33% examples, 1418072 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:49:43: EPOCH 23 - PROGRESS: at 59.10% examples, 1374389 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:44: EPOCH 23 - PROGRESS: at 88.94% examples, 1332878 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:49:45: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:45: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:45: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:45: EPOCH - 23 : training on 5876081 raw words (4680845 effective words) took 3.5s, 1328158 effective words/s\n",
      "INFO - 18:49:46: EPOCH 24 - PROGRESS: at 24.52% examples, 1359008 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:47: EPOCH 24 - PROGRESS: at 56.73% examples, 1322014 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:48: EPOCH 24 - PROGRESS: at 87.66% examples, 1308894 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:49:48: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:48: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:48: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:48: EPOCH - 24 : training on 5876081 raw words (4680688 effective words) took 3.6s, 1299450 effective words/s\n",
      "INFO - 18:49:49: EPOCH 25 - PROGRESS: at 23.58% examples, 1324217 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:49:50: EPOCH 25 - PROGRESS: at 58.00% examples, 1349923 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:51: EPOCH 25 - PROGRESS: at 88.95% examples, 1331535 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:49:52: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:52: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:52: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:52: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:52: EPOCH - 25 : training on 5876081 raw words (4680534 effective words) took 3.5s, 1341226 effective words/s\n",
      "INFO - 18:49:53: EPOCH 26 - PROGRESS: at 25.61% examples, 1436224 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:54: EPOCH 26 - PROGRESS: at 60.43% examples, 1402295 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:49:55: EPOCH 26 - PROGRESS: at 90.51% examples, 1366930 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:49:55: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:55: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:55: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:55: EPOCH - 26 : training on 5876081 raw words (4681144 effective words) took 3.4s, 1362505 effective words/s\n",
      "INFO - 18:49:56: EPOCH 27 - PROGRESS: at 25.20% examples, 1400670 words/s, in_qsize 11, out_qsize 1\n",
      "INFO - 18:49:57: EPOCH 27 - PROGRESS: at 59.27% examples, 1374241 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:49:58: EPOCH 27 - PROGRESS: at 89.67% examples, 1344013 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:49:59: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:49:59: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:49:59: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:49:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:49:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:49:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:49:59: EPOCH - 27 : training on 5876081 raw words (4681160 effective words) took 3.5s, 1351268 effective words/s\n",
      "INFO - 18:50:00: EPOCH 28 - PROGRESS: at 23.13% examples, 1294144 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:01: EPOCH 28 - PROGRESS: at 54.51% examples, 1279271 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:02: EPOCH 28 - PROGRESS: at 86.75% examples, 1285825 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:02: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:02: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:02: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:02: EPOCH - 28 : training on 5876081 raw words (4680609 effective words) took 3.6s, 1302276 effective words/s\n",
      "INFO - 18:50:03: EPOCH 29 - PROGRESS: at 26.00% examples, 1444955 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:04: EPOCH 29 - PROGRESS: at 60.41% examples, 1392844 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:50:05: EPOCH 29 - PROGRESS: at 91.23% examples, 1377322 words/s, in_qsize 11, out_qsize 1\n",
      "INFO - 18:50:06: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:06: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:06: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:06: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:06: EPOCH - 29 : training on 5876081 raw words (4680375 effective words) took 3.4s, 1381048 effective words/s\n",
      "INFO - 18:50:07: EPOCH 30 - PROGRESS: at 25.77% examples, 1437139 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:08: EPOCH 30 - PROGRESS: at 61.25% examples, 1413234 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:09: EPOCH 30 - PROGRESS: at 91.17% examples, 1375621 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:09: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:09: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:09: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:09: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:09: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:09: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:09: EPOCH - 30 : training on 5876081 raw words (4680866 effective words) took 3.4s, 1371773 effective words/s\n",
      "INFO - 18:50:10: EPOCH 31 - PROGRESS: at 24.77% examples, 1383934 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:11: EPOCH 31 - PROGRESS: at 57.11% examples, 1334397 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:12: EPOCH 31 - PROGRESS: at 86.57% examples, 1281456 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:13: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:13: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:13: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:13: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:13: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:13: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:13: EPOCH - 31 : training on 5876081 raw words (4679738 effective words) took 3.6s, 1296452 effective words/s\n",
      "INFO - 18:50:14: EPOCH 32 - PROGRESS: at 25.88% examples, 1449365 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:15: EPOCH 32 - PROGRESS: at 60.23% examples, 1402594 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:16: EPOCH 32 - PROGRESS: at 89.93% examples, 1356651 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:50:16: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:16: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:16: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:16: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:16: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:16: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:16: EPOCH - 32 : training on 5876081 raw words (4680894 effective words) took 3.4s, 1362890 effective words/s\n",
      "INFO - 18:50:17: EPOCH 33 - PROGRESS: at 24.77% examples, 1386509 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:50:18: EPOCH 33 - PROGRESS: at 58.34% examples, 1359435 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:19: EPOCH 33 - PROGRESS: at 89.18% examples, 1340036 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:20: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:20: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:20: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:20: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:20: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:20: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:20: EPOCH - 33 : training on 5876081 raw words (4680551 effective words) took 3.5s, 1345910 effective words/s\n",
      "INFO - 18:50:21: EPOCH 34 - PROGRESS: at 23.92% examples, 1332662 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:50:22: EPOCH 34 - PROGRESS: at 55.63% examples, 1299506 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:23: EPOCH 34 - PROGRESS: at 88.10% examples, 1315880 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:50:23: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:23: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:23: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:23: EPOCH - 34 : training on 5876081 raw words (4680720 effective words) took 3.5s, 1323488 effective words/s\n",
      "INFO - 18:50:24: EPOCH 35 - PROGRESS: at 25.49% examples, 1422245 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:25: EPOCH 35 - PROGRESS: at 59.08% examples, 1371623 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:50:26: EPOCH 35 - PROGRESS: at 89.37% examples, 1343880 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:27: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:27: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:27: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:27: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:27: EPOCH - 35 : training on 5876081 raw words (4680419 effective words) took 3.5s, 1337941 effective words/s\n",
      "INFO - 18:50:28: EPOCH 36 - PROGRESS: at 24.90% examples, 1386064 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:50:29: EPOCH 36 - PROGRESS: at 59.08% examples, 1376498 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:50:30: EPOCH 36 - PROGRESS: at 88.76% examples, 1330033 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:30: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:30: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:30: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:30: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:30: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:30: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:30: EPOCH - 36 : training on 5876081 raw words (4680297 effective words) took 3.5s, 1332126 effective words/s\n",
      "INFO - 18:50:31: EPOCH 37 - PROGRESS: at 24.81% examples, 1382372 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:50:32: EPOCH 37 - PROGRESS: at 58.34% examples, 1360252 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:33: EPOCH 37 - PROGRESS: at 89.09% examples, 1338243 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:34: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:34: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:34: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:34: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:34: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:34: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:34: EPOCH - 37 : training on 5876081 raw words (4680971 effective words) took 3.5s, 1341705 effective words/s\n",
      "INFO - 18:50:35: EPOCH 38 - PROGRESS: at 26.00% examples, 1455567 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:36: EPOCH 38 - PROGRESS: at 60.82% examples, 1410736 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:37: EPOCH 38 - PROGRESS: at 91.33% examples, 1383699 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:37: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:37: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:37: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:37: EPOCH - 38 : training on 5876081 raw words (4682073 effective words) took 3.4s, 1374443 effective words/s\n",
      "INFO - 18:50:38: EPOCH 39 - PROGRESS: at 25.61% examples, 1422419 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:39: EPOCH 39 - PROGRESS: at 58.17% examples, 1348420 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:40: EPOCH 39 - PROGRESS: at 87.92% examples, 1305903 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:41: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:41: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:41: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:41: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:41: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:41: EPOCH - 39 : training on 5876081 raw words (4681020 effective words) took 3.6s, 1306629 effective words/s\n",
      "INFO - 18:50:42: EPOCH 40 - PROGRESS: at 24.92% examples, 1396280 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:50:43: EPOCH 40 - PROGRESS: at 58.14% examples, 1360595 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:44: EPOCH 40 - PROGRESS: at 88.50% examples, 1328236 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:50:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:44: EPOCH - 40 : training on 5876081 raw words (4681104 effective words) took 3.6s, 1318429 effective words/s\n",
      "INFO - 18:50:45: EPOCH 41 - PROGRESS: at 23.73% examples, 1323484 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:46: EPOCH 41 - PROGRESS: at 55.84% examples, 1297558 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:47: EPOCH 41 - PROGRESS: at 88.76% examples, 1323535 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:48: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:48: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:48: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:48: EPOCH - 41 : training on 5876081 raw words (4680119 effective words) took 3.5s, 1330983 effective words/s\n",
      "INFO - 18:50:49: EPOCH 42 - PROGRESS: at 25.77% examples, 1436150 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:50: EPOCH 42 - PROGRESS: at 57.99% examples, 1352820 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:51: EPOCH 42 - PROGRESS: at 89.55% examples, 1351196 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:51: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:51: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:51: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:51: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:51: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:51: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:51: EPOCH - 42 : training on 5876081 raw words (4680118 effective words) took 3.5s, 1355566 effective words/s\n",
      "INFO - 18:50:52: EPOCH 43 - PROGRESS: at 25.20% examples, 1405069 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:53: EPOCH 43 - PROGRESS: at 59.27% examples, 1379148 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:54: EPOCH 43 - PROGRESS: at 90.38% examples, 1362565 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:50:55: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:55: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:55: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:55: EPOCH - 43 : training on 5876081 raw words (4679897 effective words) took 3.4s, 1367707 effective words/s\n",
      "INFO - 18:50:56: EPOCH 44 - PROGRESS: at 25.61% examples, 1434164 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:50:57: EPOCH 44 - PROGRESS: at 60.43% examples, 1409182 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:58: EPOCH 44 - PROGRESS: at 91.23% examples, 1387511 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:50:58: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:50:58: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:50:58: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:50:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:50:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:50:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:50:58: EPOCH - 44 : training on 5876081 raw words (4680863 effective words) took 3.4s, 1388195 effective words/s\n",
      "INFO - 18:50:59: EPOCH 45 - PROGRESS: at 26.89% examples, 1470243 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:51:00: EPOCH 45 - PROGRESS: at 62.40% examples, 1435494 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:51:01: EPOCH 45 - PROGRESS: at 92.32% examples, 1393077 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:51:02: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:02: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:02: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:02: EPOCH - 45 : training on 5876081 raw words (4681167 effective words) took 3.4s, 1378961 effective words/s\n",
      "INFO - 18:51:03: EPOCH 46 - PROGRESS: at 25.20% examples, 1391798 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:51:04: EPOCH 46 - PROGRESS: at 58.73% examples, 1362044 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:05: EPOCH 46 - PROGRESS: at 89.17% examples, 1336050 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:51:05: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:05: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:05: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:05: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:05: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:05: EPOCH - 46 : training on 5876081 raw words (4680917 effective words) took 3.5s, 1339936 effective words/s\n",
      "INFO - 18:51:06: EPOCH 47 - PROGRESS: at 24.62% examples, 1365881 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:51:07: EPOCH 47 - PROGRESS: at 59.27% examples, 1379562 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:51:08: EPOCH 47 - PROGRESS: at 89.39% examples, 1347932 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:09: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:09: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:09: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:09: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:09: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:09: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:09: EPOCH - 47 : training on 5876081 raw words (4680587 effective words) took 3.5s, 1352767 effective words/s\n",
      "INFO - 18:51:10: EPOCH 48 - PROGRESS: at 24.67% examples, 1366298 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:11: EPOCH 48 - PROGRESS: at 53.16% examples, 1238972 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:12: EPOCH 48 - PROGRESS: at 84.92% examples, 1225624 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:12: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:12: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:12: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:12: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:12: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:12: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:12: EPOCH - 48 : training on 5876081 raw words (4680306 effective words) took 3.8s, 1238598 effective words/s\n",
      "INFO - 18:51:13: EPOCH 49 - PROGRESS: at 23.39% examples, 1300813 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:51:14: EPOCH 49 - PROGRESS: at 56.72% examples, 1316802 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:51:15: EPOCH 49 - PROGRESS: at 88.95% examples, 1327097 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:16: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:16: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:16: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:16: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:16: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:16: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:16: EPOCH - 49 : training on 5876081 raw words (4680388 effective words) took 3.5s, 1335714 effective words/s\n",
      "INFO - 18:51:17: EPOCH 50 - PROGRESS: at 25.61% examples, 1436730 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:18: EPOCH 50 - PROGRESS: at 59.45% examples, 1385916 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:51:19: EPOCH 50 - PROGRESS: at 88.45% examples, 1324458 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:51:19: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:19: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:19: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:19: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:19: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:19: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:19: EPOCH - 50 : training on 5876081 raw words (4681047 effective words) took 3.5s, 1333811 effective words/s\n",
      "INFO - 18:51:20: EPOCH 51 - PROGRESS: at 25.21% examples, 1408660 words/s, in_qsize 12, out_qsize 2\n",
      "INFO - 18:51:21: EPOCH 51 - PROGRESS: at 59.45% examples, 1386380 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:51:22: EPOCH 51 - PROGRESS: at 89.39% examples, 1348384 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:51:23: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:23: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:23: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:23: EPOCH - 51 : training on 5876081 raw words (4681473 effective words) took 3.5s, 1355265 effective words/s\n",
      "INFO - 18:51:24: EPOCH 52 - PROGRESS: at 25.33% examples, 1413792 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:25: EPOCH 52 - PROGRESS: at 58.34% examples, 1358982 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:51:26: EPOCH 52 - PROGRESS: at 89.56% examples, 1349562 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:51:26: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:26: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:26: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:26: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:26: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:26: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:26: EPOCH - 52 : training on 5876081 raw words (4680833 effective words) took 3.5s, 1344642 effective words/s\n",
      "INFO - 18:51:27: EPOCH 53 - PROGRESS: at 22.31% examples, 1274574 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:28: EPOCH 53 - PROGRESS: at 56.72% examples, 1326144 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:29: EPOCH 53 - PROGRESS: at 88.86% examples, 1332362 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:30: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:30: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:30: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:30: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:30: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:30: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:30: EPOCH - 53 : training on 5876081 raw words (4680915 effective words) took 3.5s, 1323983 effective words/s\n",
      "INFO - 18:51:31: EPOCH 54 - PROGRESS: at 24.92% examples, 1388299 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:32: EPOCH 54 - PROGRESS: at 59.08% examples, 1377089 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:51:33: EPOCH 54 - PROGRESS: at 88.76% examples, 1329227 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:33: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:33: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:33: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:33: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:33: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:33: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:33: EPOCH - 54 : training on 5876081 raw words (4680581 effective words) took 3.5s, 1330663 effective words/s\n",
      "INFO - 18:51:34: EPOCH 55 - PROGRESS: at 25.72% examples, 1435774 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:51:35: EPOCH 55 - PROGRESS: at 57.97% examples, 1354471 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:36: EPOCH 55 - PROGRESS: at 88.95% examples, 1336163 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:37: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:37: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:37: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:37: EPOCH - 55 : training on 5876081 raw words (4681009 effective words) took 3.5s, 1337824 effective words/s\n",
      "INFO - 18:51:38: EPOCH 56 - PROGRESS: at 25.61% examples, 1424224 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:39: EPOCH 56 - PROGRESS: at 59.46% examples, 1385144 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:40: EPOCH 56 - PROGRESS: at 90.67% examples, 1372908 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:40: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:40: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:40: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:40: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:40: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:40: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:40: EPOCH - 56 : training on 5876081 raw words (4680781 effective words) took 3.4s, 1375195 effective words/s\n",
      "INFO - 18:51:41: EPOCH 57 - PROGRESS: at 25.88% examples, 1444161 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:42: EPOCH 57 - PROGRESS: at 61.01% examples, 1415587 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:51:43: EPOCH 57 - PROGRESS: at 91.39% examples, 1387976 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:44: EPOCH - 57 : training on 5876081 raw words (4680093 effective words) took 3.4s, 1379564 effective words/s\n",
      "INFO - 18:51:45: EPOCH 58 - PROGRESS: at 25.61% examples, 1436439 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:46: EPOCH 58 - PROGRESS: at 59.61% examples, 1389300 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:47: EPOCH 58 - PROGRESS: at 89.09% examples, 1338571 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:51:47: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:47: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:47: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:47: EPOCH - 58 : training on 5876081 raw words (4681292 effective words) took 3.5s, 1337568 effective words/s\n",
      "INFO - 18:51:48: EPOCH 59 - PROGRESS: at 24.92% examples, 1379707 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:51:49: EPOCH 59 - PROGRESS: at 59.08% examples, 1373669 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:50: EPOCH 59 - PROGRESS: at 88.86% examples, 1331877 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:51: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:51: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:51: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:51: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:51: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:51: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:51: EPOCH - 59 : training on 5876081 raw words (4680469 effective words) took 3.5s, 1333862 effective words/s\n",
      "INFO - 18:51:52: EPOCH 60 - PROGRESS: at 24.34% examples, 1354417 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:51:53: EPOCH 60 - PROGRESS: at 57.45% examples, 1336400 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:51:54: EPOCH 60 - PROGRESS: at 89.09% examples, 1336405 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:54: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:54: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:54: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:54: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:54: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:54: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:54: EPOCH - 60 : training on 5876081 raw words (4680742 effective words) took 3.5s, 1347487 effective words/s\n",
      "INFO - 18:51:55: EPOCH 61 - PROGRESS: at 25.61% examples, 1437254 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:51:56: EPOCH 61 - PROGRESS: at 60.64% examples, 1414983 words/s, in_qsize 12, out_qsize 2\n",
      "INFO - 18:51:57: EPOCH 61 - PROGRESS: at 91.90% examples, 1398574 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:51:58: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:51:58: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:51:58: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:51:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:51:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:51:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:51:58: EPOCH - 61 : training on 5876081 raw words (4680876 effective words) took 3.3s, 1405427 effective words/s\n",
      "INFO - 18:51:59: EPOCH 62 - PROGRESS: at 27.83% examples, 1490699 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:00: EPOCH 62 - PROGRESS: at 61.26% examples, 1414102 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:52:01: EPOCH 62 - PROGRESS: at 92.78% examples, 1397939 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:01: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:01: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:01: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:01: EPOCH - 62 : training on 5876081 raw words (4679862 effective words) took 3.4s, 1388443 effective words/s\n",
      "INFO - 18:52:02: EPOCH 63 - PROGRESS: at 24.06% examples, 1336472 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:03: EPOCH 63 - PROGRESS: at 56.40% examples, 1311978 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:52:04: EPOCH 63 - PROGRESS: at 88.64% examples, 1322851 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:04: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:04: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:04: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:04: EPOCH - 63 : training on 5876081 raw words (4680655 effective words) took 3.5s, 1334244 effective words/s\n",
      "INFO - 18:52:05: EPOCH 64 - PROGRESS: at 24.67% examples, 1371102 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:06: EPOCH 64 - PROGRESS: at 58.90% examples, 1373228 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:07: EPOCH 64 - PROGRESS: at 90.39% examples, 1360061 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:08: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:08: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:08: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:08: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:08: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:08: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:08: EPOCH - 64 : training on 5876081 raw words (4679767 effective words) took 3.4s, 1364014 effective words/s\n",
      "INFO - 18:52:09: EPOCH 65 - PROGRESS: at 25.88% examples, 1450510 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:10: EPOCH 65 - PROGRESS: at 59.43% examples, 1386755 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:52:11: EPOCH 65 - PROGRESS: at 89.09% examples, 1340466 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:11: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:11: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:11: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:11: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:11: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:11: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:11: EPOCH - 65 : training on 5876081 raw words (4681190 effective words) took 3.5s, 1352004 effective words/s\n",
      "INFO - 18:52:12: EPOCH 66 - PROGRESS: at 25.05% examples, 1398003 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:13: EPOCH 66 - PROGRESS: at 59.08% examples, 1378303 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:14: EPOCH 66 - PROGRESS: at 90.07% examples, 1360505 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:15: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:15: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:15: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:15: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:15: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:15: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:15: EPOCH - 66 : training on 5876081 raw words (4680060 effective words) took 3.4s, 1366716 effective words/s\n",
      "INFO - 18:52:16: EPOCH 67 - PROGRESS: at 24.36% examples, 1358722 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:17: EPOCH 67 - PROGRESS: at 57.83% examples, 1349442 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:18: EPOCH 67 - PROGRESS: at 89.27% examples, 1347465 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:52:18: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:18: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:18: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:18: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:18: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:18: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:18: EPOCH - 67 : training on 5876081 raw words (4680106 effective words) took 3.5s, 1339444 effective words/s\n",
      "INFO - 18:52:19: EPOCH 68 - PROGRESS: at 24.90% examples, 1391844 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:20: EPOCH 68 - PROGRESS: at 59.61% examples, 1390127 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:21: EPOCH 68 - PROGRESS: at 90.38% examples, 1367369 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:22: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:22: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:22: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:22: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:22: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:22: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:22: EPOCH - 68 : training on 5876081 raw words (4681659 effective words) took 3.4s, 1368227 effective words/s\n",
      "INFO - 18:52:23: EPOCH 69 - PROGRESS: at 24.18% examples, 1351653 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:24: EPOCH 69 - PROGRESS: at 58.73% examples, 1369610 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:25: EPOCH 69 - PROGRESS: at 89.49% examples, 1351382 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:25: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:25: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:25: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:25: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:25: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:25: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:25: EPOCH - 69 : training on 5876081 raw words (4681292 effective words) took 3.5s, 1353311 effective words/s\n",
      "INFO - 18:52:26: EPOCH 70 - PROGRESS: at 25.05% examples, 1398588 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:27: EPOCH 70 - PROGRESS: at 59.82% examples, 1395893 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:28: EPOCH 70 - PROGRESS: at 90.24% examples, 1366826 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:29: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:29: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:29: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:29: EPOCH - 70 : training on 5876081 raw words (4681716 effective words) took 3.4s, 1363710 effective words/s\n",
      "INFO - 18:52:30: EPOCH 71 - PROGRESS: at 24.18% examples, 1347800 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:31: EPOCH 71 - PROGRESS: at 58.14% examples, 1352977 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:32: EPOCH 71 - PROGRESS: at 89.66% examples, 1352178 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:32: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:32: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:32: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:32: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:32: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:32: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:32: EPOCH - 71 : training on 5876081 raw words (4681294 effective words) took 3.5s, 1352490 effective words/s\n",
      "INFO - 18:52:33: EPOCH 72 - PROGRESS: at 25.61% examples, 1432706 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:34: EPOCH 72 - PROGRESS: at 58.14% examples, 1353466 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:52:35: EPOCH 72 - PROGRESS: at 88.45% examples, 1319073 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:36: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:36: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:36: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:36: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:36: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:36: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:36: EPOCH - 72 : training on 5876081 raw words (4680783 effective words) took 3.5s, 1335716 effective words/s\n",
      "INFO - 18:52:37: EPOCH 73 - PROGRESS: at 24.81% examples, 1374476 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:38: EPOCH 73 - PROGRESS: at 58.34% examples, 1358769 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:39: EPOCH 73 - PROGRESS: at 89.36% examples, 1341875 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:39: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:39: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:39: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:39: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:39: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:39: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:39: EPOCH - 73 : training on 5876081 raw words (4680541 effective words) took 3.5s, 1353445 effective words/s\n",
      "INFO - 18:52:40: EPOCH 74 - PROGRESS: at 25.49% examples, 1428045 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:41: EPOCH 74 - PROGRESS: at 59.61% examples, 1386803 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:42: EPOCH 74 - PROGRESS: at 90.93% examples, 1375712 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:42: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:42: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:42: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:42: EPOCH - 74 : training on 5876081 raw words (4681966 effective words) took 3.4s, 1362301 effective words/s\n",
      "INFO - 18:52:44: EPOCH 75 - PROGRESS: at 24.21% examples, 1327688 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:45: EPOCH 75 - PROGRESS: at 57.45% examples, 1331562 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:46: EPOCH 75 - PROGRESS: at 89.96% examples, 1349659 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:46: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:46: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:46: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:46: EPOCH - 75 : training on 5876081 raw words (4679870 effective words) took 3.4s, 1357233 effective words/s\n",
      "INFO - 18:52:47: EPOCH 76 - PROGRESS: at 26.82% examples, 1483527 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:52:48: EPOCH 76 - PROGRESS: at 62.02% examples, 1441353 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:52:49: EPOCH 76 - PROGRESS: at 93.66% examples, 1419562 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:49: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:49: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:49: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:49: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:49: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:49: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:49: EPOCH - 76 : training on 5876081 raw words (4679970 effective words) took 3.3s, 1418087 effective words/s\n",
      "INFO - 18:52:50: EPOCH 77 - PROGRESS: at 25.33% examples, 1412250 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:52:51: EPOCH 77 - PROGRESS: at 59.08% examples, 1378045 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:52:52: EPOCH 77 - PROGRESS: at 90.81% examples, 1373306 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:53: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:53: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:53: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:53: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:53: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:53: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:53: EPOCH - 77 : training on 5876081 raw words (4681484 effective words) took 3.4s, 1366299 effective words/s\n",
      "INFO - 18:52:54: EPOCH 78 - PROGRESS: at 25.33% examples, 1407528 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:55: EPOCH 78 - PROGRESS: at 58.33% examples, 1356083 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:56: EPOCH 78 - PROGRESS: at 90.37% examples, 1362766 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:56: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:56: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:56: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:56: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:56: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:56: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:56: EPOCH - 78 : training on 5876081 raw words (4680177 effective words) took 3.4s, 1366194 effective words/s\n",
      "INFO - 18:52:57: EPOCH 79 - PROGRESS: at 25.72% examples, 1434390 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:52:58: EPOCH 79 - PROGRESS: at 61.29% examples, 1421536 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:52:59: EPOCH 79 - PROGRESS: at 92.11% examples, 1396339 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:52:59: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:00: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:00: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:00: EPOCH - 79 : training on 5876081 raw words (4681100 effective words) took 3.4s, 1385792 effective words/s\n",
      "INFO - 18:53:01: EPOCH 80 - PROGRESS: at 21.07% examples, 1213289 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:02: EPOCH 80 - PROGRESS: at 55.41% examples, 1293195 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:53:03: EPOCH 80 - PROGRESS: at 86.63% examples, 1283936 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:53:03: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:03: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:03: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:03: EPOCH - 80 : training on 5876081 raw words (4680820 effective words) took 3.6s, 1283869 effective words/s\n",
      "INFO - 18:53:04: EPOCH 81 - PROGRESS: at 24.52% examples, 1373037 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:53:05: EPOCH 81 - PROGRESS: at 58.91% examples, 1369887 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:06: EPOCH 81 - PROGRESS: at 88.50% examples, 1320956 words/s, in_qsize 11, out_qsize 1\n",
      "INFO - 18:53:07: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:07: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:07: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:07: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:07: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:07: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:07: EPOCH - 81 : training on 5876081 raw words (4680503 effective words) took 3.6s, 1316078 effective words/s\n",
      "INFO - 18:53:08: EPOCH 82 - PROGRESS: at 23.73% examples, 1332997 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:53:09: EPOCH 82 - PROGRESS: at 55.60% examples, 1304290 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:53:10: EPOCH 82 - PROGRESS: at 86.89% examples, 1296543 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:53:10: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:10: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:10: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:10: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:10: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:10: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:10: EPOCH - 82 : training on 5876081 raw words (4680431 effective words) took 3.6s, 1307072 effective words/s\n",
      "INFO - 18:53:11: EPOCH 83 - PROGRESS: at 26.01% examples, 1449495 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:12: EPOCH 83 - PROGRESS: at 61.88% examples, 1428059 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:13: EPOCH 83 - PROGRESS: at 92.12% examples, 1394347 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:14: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:14: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:14: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:14: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:14: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:14: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:14: EPOCH - 83 : training on 5876081 raw words (4680108 effective words) took 3.4s, 1396531 effective words/s\n",
      "INFO - 18:53:15: EPOCH 84 - PROGRESS: at 26.58% examples, 1466793 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:53:16: EPOCH 84 - PROGRESS: at 62.75% examples, 1435368 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:17: EPOCH 84 - PROGRESS: at 94.99% examples, 1423388 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:53:17: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:17: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:17: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:17: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:17: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:17: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:17: EPOCH - 84 : training on 5876081 raw words (4680470 effective words) took 3.3s, 1429948 effective words/s\n",
      "INFO - 18:53:18: EPOCH 85 - PROGRESS: at 26.36% examples, 1475971 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:53:19: EPOCH 85 - PROGRESS: at 62.55% examples, 1445924 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:20: EPOCH 85 - PROGRESS: at 93.23% examples, 1403771 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:53:20: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:20: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:20: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:20: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:20: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:20: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:20: EPOCH - 85 : training on 5876081 raw words (4680112 effective words) took 3.3s, 1398320 effective words/s\n",
      "INFO - 18:53:21: EPOCH 86 - PROGRESS: at 25.45% examples, 1419171 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:53:22: EPOCH 86 - PROGRESS: at 58.53% examples, 1360335 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:53:23: EPOCH 86 - PROGRESS: at 88.95% examples, 1331361 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:24: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:24: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:24: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:24: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:24: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:24: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:24: EPOCH - 86 : training on 5876081 raw words (4680626 effective words) took 3.5s, 1336687 effective words/s\n",
      "INFO - 18:53:25: EPOCH 87 - PROGRESS: at 25.61% examples, 1411130 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:53:26: EPOCH 87 - PROGRESS: at 60.02% examples, 1386593 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:27: EPOCH 87 - PROGRESS: at 88.76% examples, 1323209 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:53:27: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:27: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:27: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:27: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:27: EPOCH - 87 : training on 5876081 raw words (4680413 effective words) took 3.5s, 1322491 effective words/s\n",
      "INFO - 18:53:28: EPOCH 88 - PROGRESS: at 24.90% examples, 1391977 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:53:29: EPOCH 88 - PROGRESS: at 57.79% examples, 1352277 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:53:30: EPOCH 88 - PROGRESS: at 89.66% examples, 1354778 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:31: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:31: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:31: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:31: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:31: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:31: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:31: EPOCH - 88 : training on 5876081 raw words (4680730 effective words) took 3.4s, 1366705 effective words/s\n",
      "INFO - 18:53:32: EPOCH 89 - PROGRESS: at 25.61% examples, 1427296 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:33: EPOCH 89 - PROGRESS: at 60.02% examples, 1392084 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:53:34: EPOCH 89 - PROGRESS: at 91.39% examples, 1381313 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:34: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:34: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:34: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:34: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:34: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:34: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:34: EPOCH - 89 : training on 5876081 raw words (4679947 effective words) took 3.4s, 1387174 effective words/s\n",
      "INFO - 18:53:35: EPOCH 90 - PROGRESS: at 26.00% examples, 1430753 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 18:53:36: EPOCH 90 - PROGRESS: at 62.55% examples, 1439724 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:37: EPOCH 90 - PROGRESS: at 92.28% examples, 1390987 words/s, in_qsize 12, out_qsize 2\n",
      "INFO - 18:53:38: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:38: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:38: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:38: EPOCH - 90 : training on 5876081 raw words (4680767 effective words) took 3.3s, 1400072 effective words/s\n",
      "INFO - 18:53:39: EPOCH 91 - PROGRESS: at 26.36% examples, 1475970 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:53:40: EPOCH 91 - PROGRESS: at 62.18% examples, 1445149 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:41: EPOCH 91 - PROGRESS: at 93.50% examples, 1414005 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:53:41: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:41: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:41: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:41: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:41: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:41: EPOCH - 91 : training on 5876081 raw words (4680457 effective words) took 3.3s, 1414056 effective words/s\n",
      "INFO - 18:53:42: EPOCH 92 - PROGRESS: at 26.36% examples, 1475137 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:43: EPOCH 92 - PROGRESS: at 62.76% examples, 1449818 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:53:44: EPOCH 92 - PROGRESS: at 94.71% examples, 1427099 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:53:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:44: EPOCH - 92 : training on 5876081 raw words (4680130 effective words) took 3.3s, 1430533 effective words/s\n",
      "INFO - 18:53:45: EPOCH 93 - PROGRESS: at 27.92% examples, 1486964 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:53:46: EPOCH 93 - PROGRESS: at 61.69% examples, 1416019 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:47: EPOCH 93 - PROGRESS: at 92.59% examples, 1393519 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:47: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:47: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:47: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:47: EPOCH - 93 : training on 5876081 raw words (4680371 effective words) took 3.4s, 1396400 effective words/s\n",
      "INFO - 18:53:48: EPOCH 94 - PROGRESS: at 25.05% examples, 1402198 words/s, in_qsize 9, out_qsize 2\n",
      "INFO - 18:53:49: EPOCH 94 - PROGRESS: at 58.00% examples, 1356259 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:53:51: EPOCH 94 - PROGRESS: at 89.27% examples, 1346789 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:51: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:51: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:51: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:51: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:51: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:51: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:51: EPOCH - 94 : training on 5876081 raw words (4680440 effective words) took 3.5s, 1355705 effective words/s\n",
      "INFO - 18:53:52: EPOCH 95 - PROGRESS: at 26.01% examples, 1458928 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:53: EPOCH 95 - PROGRESS: at 61.88% examples, 1436272 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:53:54: EPOCH 95 - PROGRESS: at 93.04% examples, 1409882 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:54: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:54: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:54: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:54: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:54: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:54: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:54: EPOCH - 95 : training on 5876081 raw words (4681200 effective words) took 3.3s, 1413400 effective words/s\n",
      "INFO - 18:53:55: EPOCH 96 - PROGRESS: at 26.36% examples, 1474224 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:53:56: EPOCH 96 - PROGRESS: at 61.69% examples, 1429208 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:53:57: EPOCH 96 - PROGRESS: at 92.81% examples, 1401655 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:53:58: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:58: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:58: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:58: EPOCH - 96 : training on 5876081 raw words (4680036 effective words) took 3.4s, 1379611 effective words/s\n",
      "INFO - 18:53:59: EPOCH 97 - PROGRESS: at 24.67% examples, 1370164 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:54:00: EPOCH 97 - PROGRESS: at 57.08% examples, 1331785 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:54:01: EPOCH 97 - PROGRESS: at 89.18% examples, 1341023 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:54:01: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:54:01: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:54:01: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:54:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:54:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:54:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:54:01: EPOCH - 97 : training on 5876081 raw words (4681062 effective words) took 3.5s, 1334342 effective words/s\n",
      "INFO - 18:54:02: EPOCH 98 - PROGRESS: at 24.52% examples, 1372210 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:54:03: EPOCH 98 - PROGRESS: at 59.45% examples, 1389248 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:54:04: EPOCH 98 - PROGRESS: at 90.78% examples, 1377978 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:54:05: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:54:05: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:54:05: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:54:05: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:54:05: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:54:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:54:05: EPOCH - 98 : training on 5876081 raw words (4681102 effective words) took 3.4s, 1383970 effective words/s\n",
      "INFO - 18:54:06: EPOCH 99 - PROGRESS: at 26.13% examples, 1457514 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:54:07: EPOCH 99 - PROGRESS: at 61.69% examples, 1429023 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:54:08: EPOCH 99 - PROGRESS: at 91.52% examples, 1390938 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 18:54:08: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:54:08: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:54:08: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:54:08: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:54:08: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:54:08: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:54:08: EPOCH - 99 : training on 5876081 raw words (4679861 effective words) took 3.4s, 1389356 effective words/s\n",
      "INFO - 18:54:09: EPOCH 100 - PROGRESS: at 26.00% examples, 1451559 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 18:54:10: EPOCH 100 - PROGRESS: at 62.04% examples, 1424492 words/s, in_qsize 11, out_qsize 4\n",
      "INFO - 18:54:11: EPOCH 100 - PROGRESS: at 93.85% examples, 1411074 words/s, in_qsize 10, out_qsize 1\n",
      "INFO - 18:54:11: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:54:11: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:54:11: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:54:11: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:54:11: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:54:11: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:54:11: EPOCH - 100 : training on 5876081 raw words (4680745 effective words) took 3.3s, 1406799 effective words/s\n",
      "INFO - 18:54:11: training on a 587608100 raw words (468066948 effective words) took 347.6s, 1346690 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(468066948, 587608100)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_pozytywizm.train(sentences, total_examples=len(sentences), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zapisuję model, aby później nie musieć go ponownie estymować:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 19:01:37: storing 76645x100 projection weights into w2v_pozytywizm_full_forms.bin\n",
      "WARNING - 19:01:37: this function is deprecated, use smart_open.open instead\n"
     ]
    }
   ],
   "source": [
    "w2v_pozytywizm.wv.save_word2vec_format('w2v_pozytywizm_full_forms.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Załadowanie modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_pozytywizm_from_bin = KeyedVectors.load_word2vec_format(\"w2v_pozytywizm_full_forms.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W przeciwieństwie do języka angielskiego język polski ma bogatą fleksję, a co za tym idzie mnogość form, w których wyrazy mogą występować. Poniżej sprawdzam czy pary podobnych wyrazów (w mianowniku) zachowują się tak samo w innych przypadkach. 'kobieta' w mianowniku jest podobna do innych słów niż 'kobieta' w liczbie mnogiej w mianowniku:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dziewczyna', 0.8108365535736084),\n",
       " ('dama', 0.7211305499076843),\n",
       " ('osoba', 0.6993241310119629),\n",
       " ('ona', 0.6743534207344055),\n",
       " ('kobiecina', 0.6726367473602295),\n",
       " ('panienka', 0.6462386250495911),\n",
       " ('niewiasta', 0.64083331823349),\n",
       " ('istota', 0.6300680041313171),\n",
       " ('staruszka', 0.6248067021369934),\n",
       " ('matka', 0.6160675883293152)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_pozytywizm_from_bin.most_similar('kobieta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ludziom', 0.6518710851669312),\n",
       " ('mężczyznom', 0.5133285522460938),\n",
       " ('im', 0.49633872509002686),\n",
       " ('dzieciom', 0.4645894169807434),\n",
       " ('narodom', 0.4531635642051697),\n",
       " ('dostępnych', 0.43775635957717896),\n",
       " ('niewiastom', 0.4182112514972687),\n",
       " ('nam', 0.4173569977283478),\n",
       " ('niedostateczne', 0.41671890020370483),\n",
       " ('mężowi', 0.4144447445869446)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_pozytywizm_from_bin.most_similar('kobietom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ludziom', 0.8259347677230835),\n",
       " ('mężczyznom', 0.7566635608673096),\n",
       " ('im', 0.7481686472892761),\n",
       " ('dzieciom', 0.732293963432312),\n",
       " ('narodom', 0.7265810966491699),\n",
       " ('dostępnych', 0.7188774347305298),\n",
       " ('niewiastom', 0.7091049551963806),\n",
       " ('nam', 0.7086778283119202),\n",
       " ('niedostateczne', 0.7083588242530823),\n",
       " ('mężowi', 0.7072216868400574)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_pozytywizm_from_bin.most_similar('kobietom')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
